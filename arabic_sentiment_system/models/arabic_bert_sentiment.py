# Ù†Ù…Ø§Ø°Ø¬ BERT Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
# Arabic BERT Models for Sentiment Analysis

import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import (
    AutoTokenizer, AutoModel, AutoConfig,
    BertTokenizer, BertModel, BertConfig,
    TrainingArguments, Trainer, EarlyStoppingCallback
)
from transformers.modeling_outputs import SequenceClassifierOutput
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
from typing import Dict, List, Tuple, Optional, Any, Union
import logging
from dataclasses import dataclass
import json
import os
from datetime import datetime
import pickle

from ..config.settings import settings
from ..utils.arabic_text_processor import ArabicTextProcessor, TextProcessingConfig

logger = logging.getLogger(__name__)

@dataclass
class SentimentModelConfig:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    model_name: str = "aubmindlab/bert-base-arabert"
    num_labels: int = 3  # positive, negative, neutral
    max_length: int = 512
    dropout_rate: float = 0.3
    hidden_size: int = 768
    learning_rate: float = 2e-5
    batch_size: int = 16
    epochs: int = 5
    warmup_steps: int = 500
    weight_decay: float = 0.01
    fp16: bool = True  # Ø§Ø³ØªØ®Ø¯Ø§Ù… precision Ù…Ø®ØªÙ„Ø·
    gradient_accumulation_steps: int = 2

class ArabicBertSentimentClassifier(nn.Module):
    """Ù†Ù…ÙˆØ°Ø¬ BERT Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    
    def __init__(self, config: SentimentModelConfig):
        super().__init__()
        self.config = config
        
        # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ BERT Ø§Ù„Ø¹Ø±Ø¨ÙŠ
        self.bert_config = AutoConfig.from_pretrained(
            config.model_name,
            num_labels=config.num_labels,
            output_attentions=False,
            output_hidden_states=True,
        )
        
        self.bert = AutoModel.from_pretrained(
            config.model_name,
            config=self.bert_config
        )
        
        # Ø·Ø¨Ù‚Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ
        self.dropout = nn.Dropout(config.dropout_rate)
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø¨Ù‚Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù„ØªØ­Ø³ÙŠÙ†
        self.classifier_layers = nn.ModuleList([
            nn.Linear(config.hidden_size, config.hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(config.dropout_rate),
            nn.Linear(config.hidden_size // 2, config.hidden_size // 4),
            nn.ReLU(),
            nn.Dropout(config.dropout_rate),
            nn.Linear(config.hidden_size // 4, config.num_labels)
        ])
        
        # Ø·Ø¨Ù‚Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø«Ù‚Ø©
        self.confidence_layer = nn.Linear(config.hidden_size, 1)
        
        # Ø£ÙˆØ²Ø§Ù† Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø®ÙÙŠØ©
        self.layer_weights = nn.Parameter(torch.ones(self.bert_config.num_hidden_layers))
        
    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):
        # ØªÙ…Ø±ÙŠØ± Ø¹Ø¨Ø± BERT
        outputs = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask,
            return_dict=True
        )
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø®ÙÙŠØ©
        hidden_states = outputs.hidden_states  # (batch_size, seq_len, hidden_size)
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø®ÙÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø©
        weights = F.softmax(self.layer_weights, dim=0)
        weighted_hidden_states = torch.zeros_like(hidden_states[-1])
        
        for i, hidden_state in enumerate(hidden_states):
            weighted_hidden_states += weights[i] * hidden_state
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… [CLS] token Ù…Ù† Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
        cls_output = weighted_hidden_states[:, 0, :]  # [CLS] token
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø·Ø¨Ù‚Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ
        x = self.dropout(cls_output)
        
        for layer in self.classifier_layers:
            if isinstance(layer, nn.Linear):
                x = layer(x)
            else:
                x = layer(x)
        
        logits = x
        
        # Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©
        confidence_scores = torch.sigmoid(self.confidence_layer(cls_output))
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¥Ø°Ø§ ØªÙˆÙØ±Øª Ø§Ù„ØªØ³Ù…ÙŠØ§Øª
        loss = None
        if labels is not None:
            loss_fct = nn.CrossEntropyLoss()
            loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))
        
        return SequenceClassifierOutput(
            loss=loss,
            logits=logits,
            hidden_states=outputs.hidden_states,
            attentions=outputs.attentions,
        ), confidence_scores

class MultiDimensionalEmotionClassifier(nn.Module):
    """Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯"""
    
    def __init__(self, config: SentimentModelConfig):
        super().__init__()
        self.config = config
        
        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¹ÙˆØ§Ø·Ù Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        self.emotions = ['joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust', 'trust', 'anticipation']
        self.num_emotions = len(self.emotions)
        
        # Ù†Ù…ÙˆØ°Ø¬ BERT Ø§Ù„Ù…Ø´ØªØ±Ùƒ
        self.bert = AutoModel.from_pretrained(config.model_name)
        
        # Ø±Ø¤ÙˆØ³ ØªØµÙ†ÙŠÙ Ù…Ù†ÙØµÙ„Ø© Ù„ÙƒÙ„ Ø¹Ø§Ø·ÙØ©
        self.emotion_classifiers = nn.ModuleDict({
            emotion: nn.Sequential(
                nn.Linear(config.hidden_size, config.hidden_size // 2),
                nn.ReLU(),
                nn.Dropout(config.dropout_rate),
                nn.Linear(config.hidden_size // 2, 2)  # Ù…ÙˆØ¬ÙˆØ¯/ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯
            ) for emotion in self.emotions
        })
        
        # Ø±Ø£Ø³ Ù„Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ø§Ù… (Ø¥ÙŠØ¬Ø§Ø¨ÙŠ/Ø³Ù„Ø¨ÙŠ/Ù…Ø­Ø§ÙŠØ¯)
        self.general_classifier = nn.Sequential(
            nn.Linear(config.hidden_size, config.hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(config.dropout_rate),
            nn.Linear(config.hidden_size // 2, 3)
        )
        
        # Ø·Ø¨Ù‚Ø© Ø¯Ù…Ø¬ Ø§Ù„Ø¹ÙˆØ§Ø·Ù
        self.emotion_fusion = nn.Linear(self.num_emotions * 2, config.hidden_size // 4)
        
    def forward(self, input_ids=None, attention_mask=None, emotion_labels=None, sentiment_labels=None):
        # ØªÙ…Ø±ÙŠØ± Ø¹Ø¨Ø± BERT
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)
        cls_output = outputs.last_hidden_state[:, 0, :]  # [CLS] token
        
        # ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹ÙˆØ§Ø·Ù
        emotion_logits = {}
        emotion_probs = {}
        
        for emotion in self.emotions:
            logits = self.emotion_classifiers[emotion](cls_output)
            emotion_logits[emotion] = logits
            emotion_probs[emotion] = F.softmax(logits, dim=-1)
        
        # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø§Ù…
        sentiment_logits = self.general_classifier(cls_output)
        
        # Ø¯Ù…Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹ÙˆØ§Ø·Ù
        emotion_features = torch.cat([emotion_probs[emotion] for emotion in self.emotions], dim=-1)
        fused_emotions = self.emotion_fusion(emotion_features)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø¦Ø±
        total_loss = 0
        losses = {}
        
        if emotion_labels is not None:
            for i, emotion in enumerate(self.emotions):
                if emotion in emotion_labels:
                    emotion_loss = F.cross_entropy(
                        emotion_logits[emotion], 
                        emotion_labels[emotion]
                    )
                    losses[f'{emotion}_loss'] = emotion_loss
                    total_loss += emotion_loss
        
        if sentiment_labels is not None:
            sentiment_loss = F.cross_entropy(sentiment_logits, sentiment_labels)
            losses['sentiment_loss'] = sentiment_loss
            total_loss += sentiment_loss
        
        return {
            'total_loss': total_loss,
            'losses': losses,
            'emotion_logits': emotion_logits,
            'emotion_probs': emotion_probs,
            'sentiment_logits': sentiment_logits,
            'sentiment_probs': F.softmax(sentiment_logits, dim=-1),
            'fused_emotions': fused_emotions
        }

class ArabicSentimentAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„"""
    
    def __init__(self, config: SentimentModelConfig = None):
        self.config = config or SentimentModelConfig()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù†ØµÙŠ
        text_config = TextProcessingConfig(
            remove_diacritics=True,
            normalize_alef=True,
            handle_repetition=True
        )
        self.text_processor = ArabicTextProcessor(text_config)
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­ÙˆÙ„ Ø§Ù„Ù†ØµÙŠ
        self.tokenizer = AutoTokenizer.from_pretrained(self.config.model_name)
        
        # Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        self.sentiment_model = None
        self.emotion_model = None
        
        # Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª
        self.sentiment_labels = ['negative', 'neutral', 'positive']
        self.emotion_labels = ['joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust', 'trust', 'anticipation']
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.analysis_count = 0
        self.cache = {}
        
    def load_models(self, sentiment_model_path: str = None, emotion_model_path: str = None):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©"""
        try:
            # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
            if sentiment_model_path and os.path.exists(sentiment_model_path):
                self.sentiment_model = ArabicBertSentimentClassifier(self.config)
                self.sentiment_model.load_state_dict(torch.load(sentiment_model_path, map_location=self.device))
                self.sentiment_model.to(self.device)
                self.sentiment_model.eval()
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù†: {sentiment_model_path}")
            else:
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
                self.sentiment_model = ArabicBertSentimentClassifier(self.config)
                self.sentiment_model.to(self.device)
                logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ù…Ø´Ø§Ø¹Ø±")
            
            # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ÙˆØ§Ø·Ù
            if emotion_model_path and os.path.exists(emotion_model_path):
                self.emotion_model = MultiDimensionalEmotionClassifier(self.config)
                self.emotion_model.load_state_dict(torch.load(emotion_model_path, map_location=self.device))
                self.emotion_model.to(self.device)
                self.emotion_model.eval()
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ÙˆØ§Ø·Ù Ù…Ù†: {emotion_model_path}")
            else:
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
                self.emotion_model = MultiDimensionalEmotionClassifier(self.config)
                self.emotion_model.to(self.device)
                logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø¹ÙˆØ§Ø·Ù")
                
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {str(e)}")
            raise
    
    def preprocess_text(self, text: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ
        processed = self.text_processor.process_text(text)
        
        if not processed['is_valid']:
            return None
        
        # ØªØ±Ù…ÙŠØ² Ø§Ù„Ù†Øµ
        encoding = self.tokenizer(
            processed['normalized_text'],
            truncation=True,
            padding='max_length',
            max_length=self.config.max_length,
            return_tensors='pt'
        )
        
        return {
            'processed_text': processed,
            'encoding': encoding,
            'input_ids': encoding['input_ids'].to(self.device),
            'attention_mask': encoding['attention_mask'].to(self.device)
        }
    
    def analyze_sentiment(self, text: str, include_confidence: bool = True) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ"""
        if not self.sentiment_model:
            raise ValueError("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ØºÙŠØ± Ù…Ø­Ù…Ù„")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
        cache_key = f"sentiment_{hash(text)}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ
        preprocessed = self.preprocess_text(text)
        if not preprocessed:
            return self._empty_sentiment_result()
        
        # Ø§Ù„ØªØ­Ù„ÙŠÙ„
        with torch.no_grad():
            outputs, confidence_scores = self.sentiment_model(
                input_ids=preprocessed['input_ids'],
                attention_mask=preprocessed['attention_mask']
            )
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        probabilities = F.softmax(outputs.logits, dim=-1)
        predicted_class = torch.argmax(probabilities, dim=-1).item()
        confidence = confidence_scores.squeeze().item() if include_confidence else 1.0
        
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†ØªÙŠØ¬Ø©
        result = {
            'text': text,
            'predicted_sentiment': self.sentiment_labels[predicted_class],
            'confidence': confidence,
            'probabilities': {
                label: prob.item() 
                for label, prob in zip(self.sentiment_labels, probabilities.squeeze())
            },
            'analysis_metadata': {
                'model_used': 'arabic_bert_sentiment',
                'processing_time': 0,  # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠØ§Ø³ Ø§Ù„ÙˆÙ‚Øª
                'text_length': len(text),
                'normalized_length': len(preprocessed['processed_text']['normalized_text'])
            }
        }
        
        # Ø¥Ø¶Ø§ÙØ© ØªØ­Ù„ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ Ù…Ù† Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù†ØµÙˆØµ
        if preprocessed['processed_text']['emoji_analysis']:
            result['emoji_sentiment'] = preprocessed['processed_text']['emoji_analysis']
        
        if preprocessed['processed_text']['dialect_analysis']:
            result['dialect_info'] = preprocessed['processed_text']['dialect_analysis']
        
        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
        self.cache[cache_key] = result
        self.analysis_count += 1
        
        return result
    
    def analyze_emotions(self, text: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹ÙˆØ§Ø·Ù Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯"""
        if not self.emotion_model:
            raise ValueError("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ÙˆØ§Ø·Ù ØºÙŠØ± Ù…Ø­Ù…Ù„")
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ
        preprocessed = self.preprocess_text(text)
        if not preprocessed:
            return self._empty_emotion_result()
        
        # Ø§Ù„ØªØ­Ù„ÙŠÙ„
        with torch.no_grad():
            outputs = self.emotion_model(
                input_ids=preprocessed['input_ids'],
                attention_mask=preprocessed['attention_mask']
            )
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        emotion_results = {}
        for emotion in self.emotion_labels:
            probs = outputs['emotion_probs'][emotion].squeeze()
            emotion_results[emotion] = {
                'probability': probs[1].item(),  # Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¹Ø§Ø·ÙØ©
                'present': probs[1].item() > 0.5
            }
        
        # Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø§Ù…Ø©
        sentiment_probs = outputs['sentiment_probs'].squeeze()
        general_sentiment = {
            'predicted': self.sentiment_labels[torch.argmax(sentiment_probs).item()],
            'probabilities': {
                label: prob.item() 
                for label, prob in zip(self.sentiment_labels, sentiment_probs)
            }
        }
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ø§Ø·ÙØ© Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†Ø©
        dominant_emotion = max(emotion_results.items(), key=lambda x: x[1]['probability'])
        
        return {
            'text': text,
            'emotions': emotion_results,
            'general_sentiment': general_sentiment,
            'dominant_emotion': {
                'emotion': dominant_emotion[0],
                'probability': dominant_emotion[1]['probability']
            },
            'emotional_intensity': np.mean([v['probability'] for v in emotion_results.values()]),
            'analysis_metadata': {
                'model_used': 'multidimensional_emotion',
                'emotions_detected': sum(1 for v in emotion_results.values() if v['present']),
                'text_length': len(text)
            }
        }
    
    def comprehensive_analysis(self, text: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ø¹ÙˆØ§Ø·Ù"""
        sentiment_result = self.analyze_sentiment(text)
        emotion_result = self.analyze_emotions(text)
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        comprehensive_result = {
            'text': text,
            'sentiment_analysis': sentiment_result,
            'emotion_analysis': emotion_result,
            'summary': {
                'overall_sentiment': sentiment_result['predicted_sentiment'],
                'sentiment_confidence': sentiment_result['confidence'],
                'dominant_emotion': emotion_result['dominant_emotion'],
                'emotional_intensity': emotion_result['emotional_intensity'],
                'analysis_timestamp': datetime.now().isoformat()
            }
        }
        
        # Ø¥Ø¶Ø§ÙØ© ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…
        comprehensive_result['advanced_analysis'] = self._advanced_sentiment_analysis(
            sentiment_result, emotion_result
        )
        
        return comprehensive_result
    
    def _advanced_sentiment_analysis(self, sentiment_result: Dict, emotion_result: Dict) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… ÙŠØ¯Ù…Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ø¹ÙˆØ§Ø·Ù"""
        # Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ
        emotions_present = sum(1 for v in emotion_result['emotions'].values() if v['present'])
        emotional_complexity = emotions_present / len(self.emotion_labels)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø²Ø§Ø¬
        if sentiment_result['predicted_sentiment'] == 'positive':
            if emotion_result['dominant_emotion']['emotion'] in ['joy', 'trust', 'anticipation']:
                mood = 'upbeat'
            else:
                mood = 'cautiously_positive'
        elif sentiment_result['predicted_sentiment'] == 'negative':
            if emotion_result['dominant_emotion']['emotion'] in ['sadness', 'fear']:
                mood = 'melancholic'
            elif emotion_result['dominant_emotion']['emotion'] == 'anger':
                mood = 'aggressive'
            else:
                mood = 'negative'
        else:
            mood = 'neutral'
        
        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø§Ø³ØªØ«Ø§Ø±Ø©
        arousal_emotions = ['anger', 'fear', 'surprise', 'joy']
        arousal_score = np.mean([
            emotion_result['emotions'][emotion]['probability'] 
            for emotion in arousal_emotions
        ])
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙƒØ§ÙØ¤ (Ø¥ÙŠØ¬Ø§Ø¨ÙŠ/Ø³Ù„Ø¨ÙŠ)
        positive_emotions = ['joy', 'trust', 'anticipation']
        negative_emotions = ['sadness', 'anger', 'fear', 'disgust']
        
        positive_score = np.mean([
            emotion_result['emotions'][emotion]['probability'] 
            for emotion in positive_emotions
        ])
        negative_score = np.mean([
            emotion_result['emotions'][emotion]['probability'] 
            for emotion in negative_emotions
        ])
        
        valence = positive_score - negative_score
        
        return {
            'emotional_complexity': emotional_complexity,
            'mood_classification': mood,
            'arousal_level': arousal_score,
            'valence_score': valence,
            'emotional_coherence': abs(valence - (
                1 if sentiment_result['predicted_sentiment'] == 'positive' else 
                -1 if sentiment_result['predicted_sentiment'] == 'negative' else 0
            )),
            'analysis_confidence': (
                sentiment_result['confidence'] + 
                emotion_result['dominant_emotion']['probability']
            ) / 2
        }
    
    def _empty_sentiment_result(self) -> Dict[str, Any]:
        """Ù†ØªÙŠØ¬Ø© ÙØ§Ø±ØºØ© Ù„Ù„Ù…Ø´Ø§Ø¹Ø±"""
        return {
            'text': "",
            'predicted_sentiment': 'neutral',
            'confidence': 0.0,
            'probabilities': {label: 0.0 for label in self.sentiment_labels},
            'analysis_metadata': {'error': 'text_processing_failed'}
        }
    
    def _empty_emotion_result(self) -> Dict[str, Any]:
        """Ù†ØªÙŠØ¬Ø© ÙØ§Ø±ØºØ© Ù„Ù„Ø¹ÙˆØ§Ø·Ù"""
        return {
            'text': "",
            'emotions': {emotion: {'probability': 0.0, 'present': False} for emotion in self.emotion_labels},
            'general_sentiment': {
                'predicted': 'neutral',
                'probabilities': {label: 0.0 for label in self.sentiment_labels}
            },
            'dominant_emotion': {'emotion': 'neutral', 'probability': 0.0},
            'emotional_intensity': 0.0,
            'analysis_metadata': {'error': 'text_processing_failed'}
        }
    
    def batch_analyze(self, texts: List[str], analysis_type: str = 'comprehensive') -> List[Dict[str, Any]]:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…Ø¹ Ù„Ù„Ù†ØµÙˆØµ"""
        results = []
        
        for text in texts:
            try:
                if analysis_type == 'sentiment':
                    result = self.analyze_sentiment(text)
                elif analysis_type == 'emotion':
                    result = self.analyze_emotions(text)
                else:
                    result = self.comprehensive_analysis(text)
                
                results.append(result)
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ: {text[:50]}... - {str(e)}")
                results.append(self._empty_sentiment_result() if analysis_type == 'sentiment' 
                             else self._empty_emotion_result())
        
        return results
    
    def get_model_info(self) -> Dict[str, Any]:
        """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­Ù…Ù„Ø©"""
        return {
            'sentiment_model_loaded': self.sentiment_model is not None,
            'emotion_model_loaded': self.emotion_model is not None,
            'model_config': self.config.__dict__,
            'supported_labels': {
                'sentiment': self.sentiment_labels,
                'emotions': self.emotion_labels
            },
            'analysis_count': self.analysis_count,
            'cache_size': len(self.cache),
            'device': str(self.device)
        }

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    config = SentimentModelConfig(
        model_name="aubmindlab/bert-base-arabert",
        num_labels=3,
        max_length=256
    )
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­Ù„Ù„
    analyzer = ArabicSentimentAnalyzer(config)
    analyzer.load_models()
    
    # Ù†ØµÙˆØµ ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    test_texts = [
        "Ø£Ø­Ø¨ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø§Ù„ ÙƒØ«ÙŠØ±Ø§Ù‹! Ø¥Ù†Ù‡ Ø±Ø§Ø¦Ø¹ ÙˆÙ…ÙÙŠØ¯ Ø¬Ø¯Ø§Ù‹ ğŸ˜",
        "Ù‡Ø°Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø³ÙŠØ¡ ÙˆÙ…Ù…Ù„Ù„ØŒ Ù„Ø§ Ø£Ù†ØµØ­ Ø¨Ù‚Ø±Ø§Ø¡ØªÙ‡ ğŸ˜",
        "Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¹Ø§Ø¯ÙŠØŒ Ù„Ø§ Ø´ÙŠØ¡ Ù…Ù…ÙŠØ² ÙÙŠÙ‡",
        "Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø­Ø²Ù† ÙˆØ§Ù„Ø¥Ø­Ø¨Ø§Ø· Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ø¤Ù„Ù…",
        "ÙˆØ§Ùˆ! Ù‡Ø°Ø§ Ù…ÙØ§Ø¬Ø¦ ÙˆÙ…Ø«ÙŠØ± Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù…ØŒ Ù„Ù… Ø£ØªÙˆÙ‚Ø¹ Ø°Ù„Ùƒ!"
    ]
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ
    for text in test_texts:
        print(f"\nğŸ“ Ø§Ù„Ù†Øµ: {text}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„
        result = analyzer.comprehensive_analysis(text)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        sentiment = result['sentiment_analysis']
        emotion = result['emotion_analysis']
        advanced = result['advanced_analysis']
        
        print(f"ğŸ˜Š Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {sentiment['predicted_sentiment']} (Ø«Ù‚Ø©: {sentiment['confidence']:.2f})")
        print(f"ğŸ’­ Ø§Ù„Ø¹Ø§Ø·ÙØ© Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†Ø©: {emotion['dominant_emotion']['emotion']} ({emotion['dominant_emotion']['probability']:.2f})")
        print(f"ğŸ­ Ø§Ù„Ù…Ø²Ø§Ø¬: {advanced['mood_classification']}")
        print(f"âš¡ Ø§Ù„Ø§Ø³ØªØ«Ø§Ø±Ø©: {advanced['arousal_level']:.2f}")
        print(f"ğŸ¯ Ø§Ù„ØªÙƒØ§ÙØ¤: {advanced['valence_score']:.2f}")
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    print(f"\nğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:")
    model_info = analyzer.get_model_info()
    print(f"Ø¹Ø¯Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª: {model_info['analysis_count']}")
    print(f"Ø­Ø¬Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {model_info['cache_size']}")
    print(f"Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {model_info['device']}")
