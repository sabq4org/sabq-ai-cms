# APIs Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠ
# Arabic Sentiment Analysis System APIs

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, Request, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field, validator
from typing import List, Dict, Optional, Any, Union
from datetime import datetime, timedelta
import asyncio
import logging
import time
import hashlib
import json
from contextlib import asynccontextmanager
import uvicorn
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
import redis.asyncio as redis
from prometheus_client import Counter, Histogram, Gauge, generate_latest
import sys
import os

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from config.settings import settings, LOGGING_CONFIG
from models.arabic_bert_sentiment import ArabicSentimentAnalyzer, SentimentModelConfig
from services.analytics_service import SentimentAnalyticsService
from services.trend_analysis import TrendAnalysisService
from services.public_opinion import PublicOpinionAnalyzer

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(level=getattr(logging, settings.log_level))
logger = logging.getLogger(__name__)

# Ù…Ù‚Ø§ÙŠÙŠØ³ Prometheus
REQUEST_COUNT = Counter('sentiment_requests_total', 'Total sentiment analysis requests', ['endpoint', 'method'])
REQUEST_DURATION = Histogram('sentiment_request_duration_seconds', 'Request duration', ['endpoint'])
ACTIVE_CONNECTIONS = Gauge('sentiment_active_connections', 'Active connections')
ERROR_COUNT = Counter('sentiment_errors_total', 'Total errors', ['type'])

# Ø¥Ø¹Ø¯Ø§Ø¯ Rate Limiting
limiter = Limiter(key_func=get_remote_address)

# Security
security = HTTPBearer(auto_error=False)

# ========================= Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª =========================

class SentimentRequest(BaseModel):
    """Ø·Ù„Ø¨ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    text: str = Field(..., min_length=1, max_length=5000, description="Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡")
    analysis_type: str = Field(
        default="comprehensive", 
        regex="^(sentiment|emotion|comprehensive)$",
        description="Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨"
    )
    include_confidence: bool = Field(default=True, description="ØªØ¶Ù…ÙŠÙ† Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©")
    detect_dialect: bool = Field(default=True, description="ÙƒØ´Ù Ø§Ù„Ù„Ù‡Ø¬Ø©")
    cache_result: bool = Field(default=True, description="Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª")
    
    @validator('text')
    def validate_text(cls, v):
        if not v or len(v.strip()) == 0:
            raise ValueError('Ø§Ù„Ù†Øµ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† ÙØ§Ø±ØºØ§Ù‹')
        return v.strip()

class BatchSentimentRequest(BaseModel):
    """Ø·Ù„Ø¨ ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…Ø¹ Ù„Ù„Ù…Ø´Ø§Ø¹Ø±"""
    texts: List[str] = Field(..., min_items=1, max_items=100, description="Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ")
    analysis_type: str = Field(default="comprehensive", regex="^(sentiment|emotion|comprehensive)$")
    include_confidence: bool = Field(default=True)
    detect_dialect: bool = Field(default=True)
    
    @validator('texts')
    def validate_texts(cls, v):
        if not v:
            raise ValueError('Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† ÙØ§Ø±ØºØ©')
        
        for i, text in enumerate(v):
            if not text or len(text.strip()) == 0:
                raise ValueError(f'Ø§Ù„Ù†Øµ Ø±Ù‚Ù… {i+1} ÙØ§Ø±Øº')
            if len(text) > 5000:
                raise ValueError(f'Ø§Ù„Ù†Øµ Ø±Ù‚Ù… {i+1} Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹ (Ø£ÙƒØ«Ø± Ù…Ù† 5000 Ø­Ø±Ù)')
        
        return [text.strip() for text in v]

class TrendAnalysisRequest(BaseModel):
    """Ø·Ù„Ø¨ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª"""
    category: Optional[str] = Field(None, description="ÙØ¦Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰")
    time_range: str = Field(
        default="24h", 
        regex="^(1h|6h|12h|24h|7d|30d)$",
        description="Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù„ØªØ­Ù„ÙŠÙ„"
    )
    include_emotions: bool = Field(default=True, description="ØªØ¶Ù…ÙŠÙ† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹ÙˆØ§Ø·Ù")
    min_samples: int = Field(default=10, ge=1, le=1000, description="Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª")

class PublicOpinionRequest(BaseModel):
    """Ø·Ù„Ø¨ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù…"""
    topic: str = Field(..., min_length=2, max_length=100, description="Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡")
    sources: Optional[List[str]] = Field(None, description="Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    time_range: str = Field(default="7d", regex="^(1d|7d|30d|90d)$")
    sentiment_threshold: float = Field(default=0.6, ge=0.1, le=1.0)

class ContentMoodRequest(BaseModel):
    """Ø·Ù„Ø¨ ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø²Ø§Ø¬"""
    content: str = Field(..., min_length=10, max_length=10000)
    content_type: str = Field(
        default="article",
        regex="^(article|news|opinion|comment|social_post)$"
    )
    target_audience: Optional[str] = Field(None, regex="^(general|youth|adults|professionals)$")

# ========================= Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª =========================

class SentimentResponse(BaseModel):
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    success: bool
    data: Optional[Dict[str, Any]] = None
    message: str
    processing_time_ms: float
    timestamp: datetime
    request_id: str

class BatchSentimentResponse(BaseModel):
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù…Ø¹"""
    success: bool
    data: Optional[List[Dict[str, Any]]] = None
    total_processed: int
    successful: int
    failed: int
    processing_time_ms: float
    timestamp: datetime
    request_id: str

class ErrorResponse(BaseModel):
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø®Ø·Ø£"""
    success: bool = False
    error: str
    error_code: str
    message: str
    timestamp: datetime
    request_id: str

# ========================= Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… =========================

class SentimentSystemManager:
    """Ù…Ø¯ÙŠØ± Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    
    def __init__(self):
        self.analyzer = None
        self.analytics_service = None
        self.trend_service = None
        self.opinion_analyzer = None
        self.redis_client = None
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.request_count = 0
        self.active_requests = 0
        self.system_start_time = datetime.now()
        
    async def initialize(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±...")
        
        try:
            # ØªÙ‡ÙŠØ¦Ø© Redis
            await self._initialize_redis()
            
            # ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
            await self._initialize_sentiment_analyzer()
            
            # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
            await self._initialize_services()
            
            logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¨Ù†Ø¬Ø§Ø­")
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {str(e)}")
            raise
    
    async def _initialize_redis(self):
        """ØªÙ‡ÙŠØ¦Ø© Redis"""
        try:
            self.redis_client = redis.Redis(
                host=settings.redis_host,
                port=settings.redis_port,
                db=settings.redis_db,
                password=settings.redis_password,
                decode_responses=True
            )
            
            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„
            await self.redis_client.ping()
            logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Redis Ø¨Ù†Ø¬Ø§Ø­")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Redis: {str(e)}")
            self.redis_client = None
    
    async def _initialize_sentiment_analyzer(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
        config = SentimentModelConfig(
            model_name=settings.arabic_bert_model,
            max_length=settings.max_sequence_length,
            batch_size=settings.batch_size
        )
        
        self.analyzer = ArabicSentimentAnalyzer(config)
        self.analyzer.load_models()
        
        logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")
    
    async def _initialize_services(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©"""
        try:
            self.analytics_service = SentimentAnalyticsService(self.redis_client)
            self.trend_service = TrendAnalysisService(self.redis_client)
            self.opinion_analyzer = PublicOpinionAnalyzer(self.redis_client)
            
            logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø¨Ø¹Ø¶ Ø§Ù„Ø®Ø¯Ù…Ø§Øª: {str(e)}")
    
    async def analyze_sentiment(self, request: SentimentRequest, request_id: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
        start_time = time.time()
        
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
            if request.cache_result and self.redis_client:
                cached_result = await self._get_cached_result(request.text)
                if cached_result:
                    logger.info(f"ğŸ“¦ Ø¥Ø±Ø¬Ø§Ø¹ Ù†ØªÙŠØ¬Ø© Ù…Ø­ÙÙˆØ¸Ø© Ù„Ù„Ø·Ù„Ø¨ {request_id}")
                    return cached_result
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ
            if request.analysis_type == "sentiment":
                result = self.analyzer.analyze_sentiment(
                    request.text, 
                    include_confidence=request.include_confidence
                )
            elif request.analysis_type == "emotion":
                result = self.analyzer.analyze_emotions(request.text)
            else:
                result = self.analyzer.comprehensive_analysis(request.text)
            
            # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
            result['request_id'] = request_id
            result['processing_time_ms'] = (time.time() - start_time) * 1000
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
            if request.cache_result and self.redis_client:
                await self._cache_result(request.text, result)
            
            # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
            if self.analytics_service:
                await self.analytics_service.record_analysis(result)
            
            self.request_count += 1
            return result
            
        except Exception as e:
            ERROR_COUNT.labels(type='sentiment_analysis').inc()
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„Ù„Ø·Ù„Ø¨ {request_id}: {str(e)}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {str(e)}"
            )
    
    async def batch_analyze(self, request: BatchSentimentRequest, request_id: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…Ø¹ Ù„Ù„Ù…Ø´Ø§Ø¹Ø±"""
        start_time = time.time()
        
        try:
            results = self.analyzer.batch_analyze(
                request.texts,
                analysis_type=request.analysis_type
            )
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            successful = sum(1 for r in results if 'error' not in r.get('analysis_metadata', {}))
            failed = len(results) - successful
            
            # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
            if self.analytics_service:
                for result in results:
                    if 'error' not in result.get('analysis_metadata', {}):
                        await self.analytics_service.record_analysis(result)
            
            response_data = {
                'results': results,
                'statistics': {
                    'total_processed': len(results),
                    'successful': successful,
                    'failed': failed,
                    'success_rate': successful / len(results) if results else 0,
                    'processing_time_ms': (time.time() - start_time) * 1000
                },
                'request_id': request_id
            }
            
            self.request_count += len(request.texts)
            return response_data
            
        except Exception as e:
            ERROR_COUNT.labels(type='batch_analysis').inc()
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù…Ø¹ Ù„Ù„Ø·Ù„Ø¨ {request_id}: {str(e)}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù…Ø¹: {str(e)}"
            )
    
    async def _get_cached_result(self, text: str) -> Optional[Dict[str, Any]]:
        """Ø¬Ù„Ø¨ Ù†ØªÙŠØ¬Ø© Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        if not self.redis_client:
            return None
        
        try:
            cache_key = f"{settings.redis_key_prefix}text:{hashlib.md5(text.encode()).hexdigest()}"
            cached_data = await self.redis_client.get(cache_key)
            
            if cached_data:
                return json.loads(cached_data)
                
        except Exception as e:
            logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø© Ù…Ø¤Ù‚ØªØ§Ù‹: {str(e)}")
        
        return None
    
    async def _cache_result(self, text: str, result: Dict[str, Any]) -> bool:
        """Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        if not self.redis_client:
            return False
        
        try:
            cache_key = f"{settings.redis_key_prefix}text:{hashlib.md5(text.encode()).hexdigest()}"
            await self.redis_client.setex(
                cache_key,
                settings.cache_ttl,
                json.dumps(result, default=str)
            )
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {str(e)}")
            return False
    
    async def get_system_health(self) -> Dict[str, Any]:
        """Ø­Ø§Ù„Ø© ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        uptime = datetime.now() - self.system_start_time
        
        return {
            'status': 'healthy',
            'uptime_seconds': uptime.total_seconds(),
            'total_requests': self.request_count,
            'active_requests': self.active_requests,
            'analyzer_loaded': self.analyzer is not None,
            'redis_connected': self.redis_client is not None,
            'services_status': {
                'analytics': self.analytics_service is not None,
                'trends': self.trend_service is not None,
                'opinion': self.opinion_analyzer is not None
            },
            'timestamp': datetime.now().isoformat()
        }
    
    async def shutdown(self):
        """Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù†Ø¸Ø§Ù…"""
        logger.info("ğŸ”š Ø¨Ø¯Ø¡ Ø¥ØºÙ„Ø§Ù‚ Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±...")
        
        if self.redis_client:
            await self.redis_client.close()
        
        logger.info("âœ… ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­")

# Ù…Ø¯ÙŠØ± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø§Ù…
system_manager = SentimentSystemManager()

# ========================= Ø¥Ø¹Ø¯Ø§Ø¯ FastAPI =========================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Ø¥Ø¯Ø§Ø±Ø© Ø¯ÙˆØ±Ø© Ø­ÙŠØ§Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"""
    # Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
    await system_manager.initialize()
    yield
    # Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
    await system_manager.shutdown()

# Ø¥Ù†Ø´Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚ FastAPI
app = FastAPI(
    title="Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠ",
    description="API Ø´Ø§Ù…Ù„ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ø¹ÙˆØ§Ø·Ù ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# Ø¥Ø¶Ø§ÙØ© Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["*"]  # ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¶ÙŠÙÙŠÙ† Ø§Ù„Ù…Ø³Ù…ÙˆØ­ÙŠÙ†
)

# Ø¥Ø¶Ø§ÙØ© Rate Limiting
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# ========================= ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© =========================

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)"""
    if settings.api_key_required and not credentials:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Ù…ÙØªØ§Ø­ API Ù…Ø·Ù„ÙˆØ¨"
        )
    return credentials

def generate_request_id() -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±Ù ÙØ±ÙŠØ¯ Ù„Ù„Ø·Ù„Ø¨"""
    return f"req_{int(time.time() * 1000)}_{hashlib.md5(str(time.time()).encode()).hexdigest()[:8]}"

# ========================= Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§ÙŠØ© =========================

@app.get("/", tags=["Ø¹Ø§Ù…"])
async def root():
    """Ù†Ù‚Ø·Ø© Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¬Ø°Ø±"""
    return {
        "message": "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠ",
        "version": "1.0.0",
        "status": "active",
        "docs": "/docs",
        "features": [
            "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± (Ø¥ÙŠØ¬Ø§Ø¨ÙŠ/Ø³Ù„Ø¨ÙŠ/Ù…Ø­Ø§ÙŠØ¯)",
            "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹ÙˆØ§Ø·Ù Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯",
            "ÙƒØ´Ù Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
            "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª",
            "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù…",
            "ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø²Ø§Ø¬"
        ]
    }

@app.get("/health", tags=["Ø¹Ø§Ù…"])
async def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    health_data = await system_manager.get_system_health()
    return health_data

@app.post("/analyze/sentiment", response_model=SentimentResponse, tags=["ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"])
@limiter.limit(f"{settings.rate_limit_per_minute}/minute")
async def analyze_sentiment(
    request: Request,
    sentiment_request: SentimentRequest,
    background_tasks: BackgroundTasks,
    current_user = Depends(get_current_user)
):
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„Ù†Øµ ÙˆØ§Ø­Ø¯
    
    ÙŠØ­Ù„Ù„ Ø§Ù„Ù†Øµ ÙˆÙŠØ­Ø¯Ø¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Ù‹ Ø£Ù… Ø³Ù„Ø¨ÙŠØ§Ù‹ Ø£Ù… Ù…Ø­Ø§ÙŠØ¯Ø§Ù‹ØŒ
    Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹ÙˆØ§Ø·Ù ÙˆØ§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ù„Ù‡Ø¬Ø©.
    """
    REQUEST_COUNT.labels(endpoint='analyze_sentiment', method='POST').inc()
    
    request_id = generate_request_id()
    start_time = time.time()
    
    try:
        system_manager.active_requests += 1
        ACTIVE_CONNECTIONS.inc()
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
        with REQUEST_DURATION.labels(endpoint='analyze_sentiment').time():
            result = await system_manager.analyze_sentiment(sentiment_request, request_id)
        
        processing_time = (time.time() - start_time) * 1000
        
        return SentimentResponse(
            success=True,
            data=result,
            message="ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¨Ù†Ø¬Ø§Ø­",
            processing_time_ms=processing_time,
            timestamp=datetime.now(),
            request_id=request_id
        )
        
    except HTTPException:
        raise
    except Exception as e:
        ERROR_COUNT.labels(type='unexpected_error').inc()
        logger.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ {request_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…"
        )
    finally:
        system_manager.active_requests -= 1
        ACTIVE_CONNECTIONS.dec()

@app.post("/analyze/batch", response_model=BatchSentimentResponse, tags=["ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"])
@limiter.limit(f"{settings.rate_limit_per_minute // 10}/minute")
async def analyze_batch_sentiment(
    request: Request,
    batch_request: BatchSentimentRequest,
    background_tasks: BackgroundTasks,
    current_user = Depends(get_current_user)
):
    """
    ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…Ø¹ Ù„Ù„Ù…Ø´Ø§Ø¹Ø±
    
    ÙŠØ­Ù„Ù„ Ø¹Ø¯Ø© Ù†ØµÙˆØµ ÙÙŠ Ø·Ù„Ø¨ ÙˆØ§Ø­Ø¯ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡.
    """
    REQUEST_COUNT.labels(endpoint='analyze_batch', method='POST').inc()
    
    request_id = generate_request_id()
    start_time = time.time()
    
    try:
        system_manager.active_requests += 1
        ACTIVE_CONNECTIONS.inc()
        
        with REQUEST_DURATION.labels(endpoint='analyze_batch').time():
            result = await system_manager.batch_analyze(batch_request, request_id)
        
        processing_time = (time.time() - start_time) * 1000
        
        return BatchSentimentResponse(
            success=True,
            data=result['results'],
            total_processed=result['statistics']['total_processed'],
            successful=result['statistics']['successful'],
            failed=result['statistics']['failed'],
            processing_time_ms=processing_time,
            timestamp=datetime.now(),
            request_id=request_id
        )
        
    except HTTPException:
        raise
    except Exception as e:
        ERROR_COUNT.labels(type='unexpected_error').inc()
        logger.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù…Ø¹ {request_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…"
        )
    finally:
        system_manager.active_requests -= 1
        ACTIVE_CONNECTIONS.dec()

@app.post("/analyze/trends", tags=["Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"])
@limiter.limit(f"{settings.rate_limit_per_minute // 5}/minute")
async def analyze_trends(
    request: Request,
    trend_request: TrendAnalysisRequest,
    current_user = Depends(get_current_user)
):
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø¹Ø§Ø·ÙÙŠØ©
    
    ÙŠØ­Ù„Ù„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø¹Ø§Ø·ÙÙŠØ© Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø®Ù„Ø§Ù„ ÙØªØ±Ø© Ø²Ù…Ù†ÙŠØ© Ù…Ø­Ø¯Ø¯Ø©.
    """
    REQUEST_COUNT.labels(endpoint='analyze_trends', method='POST').inc()
    
    if not system_manager.trend_service:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Ø®Ø¯Ù…Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª ØºÙŠØ± Ù…ØªØ§Ø­Ø©"
        )
    
    try:
        result = await system_manager.trend_service.analyze_trends(
            category=trend_request.category,
            time_range=trend_request.time_range,
            include_emotions=trend_request.include_emotions,
            min_samples=trend_request.min_samples
        )
        
        return {
            "success": True,
            "data": result,
            "message": "ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø¨Ù†Ø¬Ø§Ø­",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        ERROR_COUNT.labels(type='trend_analysis').inc()
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª: {str(e)}"
        )

@app.post("/analyze/public-opinion", tags=["Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"])
@limiter.limit(f"{settings.rate_limit_per_minute // 10}/minute")
async def analyze_public_opinion(
    request: Request,
    opinion_request: PublicOpinionRequest,
    current_user = Depends(get_current_user)
):
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù…
    
    ÙŠØ­Ù„Ù„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù… Ø­ÙˆÙ„ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø¹ÙŠÙ† Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…Ø®ØªÙ„ÙØ©.
    """
    REQUEST_COUNT.labels(endpoint='analyze_opinion', method='POST').inc()
    
    if not system_manager.opinion_analyzer:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Ø®Ø¯Ù…Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù… ØºÙŠØ± Ù…ØªØ§Ø­Ø©"
        )
    
    try:
        result = await system_manager.opinion_analyzer.analyze_opinion(
            topic=opinion_request.topic,
            sources=opinion_request.sources,
            time_range=opinion_request.time_range,
            sentiment_threshold=opinion_request.sentiment_threshold
        )
        
        return {
            "success": True,
            "data": result,
            "message": "ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        ERROR_COUNT.labels(type='opinion_analysis').inc()
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù…: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù…: {str(e)}"
        )

@app.post("/classify/mood", tags=["ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"])
@limiter.limit(f"{settings.rate_limit_per_minute}/minute")
async def classify_content_mood(
    request: Request,
    mood_request: ContentMoodRequest,
    current_user = Depends(get_current_user)
):
    """
    ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø²Ø§Ø¬
    
    ÙŠØµÙ†Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¥Ù„Ù‰ ÙØ¦Ø§Øª Ù…Ø²Ø§Ø¬ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù.
    """
    REQUEST_COUNT.labels(endpoint='classify_mood', method='POST').inc()
    
    try:
        # ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø­ØªÙˆÙ‰
        analysis = system_manager.analyzer.comprehensive_analysis(mood_request.content)
        
        # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø²Ø§Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        mood_classification = _classify_content_mood(
            analysis,
            mood_request.content_type,
            mood_request.target_audience
        )
        
        return {
            "success": True,
            "data": {
                "content_analysis": analysis,
                "mood_classification": mood_classification,
                "content_type": mood_request.content_type,
                "target_audience": mood_request.target_audience
            },
            "message": "ØªÙ… ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø²Ø§Ø¬ Ø¨Ù†Ø¬Ø§Ø­",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        ERROR_COUNT.labels(type='mood_classification').inc()
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø²Ø§Ø¬: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ÙØ´Ù„ ÙÙŠ ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø²Ø§Ø¬: {str(e)}"
        )

def _classify_content_mood(analysis: Dict[str, Any], content_type: str, target_audience: Optional[str]) -> Dict[str, Any]:
    """ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø²Ø§Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
    sentiment = analysis['sentiment_analysis']['predicted_sentiment']
    emotions = analysis['emotion_analysis']['emotions']
    advanced = analysis['advanced_analysis']
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø²Ø§Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
    if sentiment == 'positive':
        if emotions['joy']['present']:
            mood = 'uplifting'
        elif emotions['trust']['present']:
            mood = 'informative'
        else:
            mood = 'positive'
    elif sentiment == 'negative':
        if emotions['anger']['present']:
            mood = 'serious'
        elif emotions['sadness']['present']:
            mood = 'emotional'
        else:
            mood = 'negative'
    else:
        mood = 'neutral'
    
    # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    if content_type == 'news' and mood == 'uplifting':
        mood = 'informative'
    elif content_type == 'entertainment':
        if mood in ['serious', 'emotional']:
            mood = 'entertaining'
    
    # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
    audience_factor = 1.0
    if target_audience == 'youth':
        audience_factor = 1.2 if mood == 'entertaining' else 0.8
    elif target_audience == 'professionals':
        audience_factor = 1.2 if mood == 'informative' else 0.8
    
    return {
        'primary_mood': mood,
        'mood_confidence': advanced['analysis_confidence'] * audience_factor,
        'suitable_for_audience': audience_factor > 1.0,
        'recommended_timing': _recommend_timing(mood, emotions),
        'content_tags': _generate_content_tags(mood, emotions, content_type)
    }

def _recommend_timing(mood: str, emotions: Dict[str, Any]) -> List[str]:
    """ØªÙˆØµÙŠØ© Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©"""
    if mood == 'uplifting':
        return ['morning', 'afternoon']
    elif mood == 'serious':
        return ['morning', 'evening']
    elif mood == 'entertaining':
        return ['afternoon', 'evening', 'weekend']
    else:
        return ['anytime']

def _generate_content_tags(mood: str, emotions: Dict[str, Any], content_type: str) -> List[str]:
    """Ø¥Ù†Ø´Ø§Ø¡ ØªØ§ØºØ§Øª Ù„Ù„Ù…Ø­ØªÙˆÙ‰"""
    tags = [mood, content_type]
    
    for emotion, data in emotions.items():
        if data['present'] and data['probability'] > 0.7:
            tags.append(emotion)
    
    return tags

@app.get("/metrics", tags=["Ù…Ø±Ø§Ù‚Ø¨Ø©"])
async def get_metrics():
    """Ù…Ù‚Ø§ÙŠÙŠØ³ Prometheus"""
    return generate_latest()

@app.get("/stats", tags=["Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"])
async def get_system_stats():
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
    health = await system_manager.get_system_health()
    
    model_info = system_manager.analyzer.get_model_info() if system_manager.analyzer else {}
    
    return {
        "system_health": health,
        "model_info": model_info,
        "performance_metrics": {
            "total_requests": system_manager.request_count,
            "active_requests": system_manager.active_requests,
            "uptime_hours": health['uptime_seconds'] / 3600
        }
    }

# ========================= Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ =========================

@app.exception_handler(ValueError)
async def value_error_handler(request: Request, exc: ValueError):
    """Ù…Ø¹Ø§Ù„Ø¬ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù‚ÙŠÙ…"""
    ERROR_COUNT.labels(type='validation_error').inc()
    return JSONResponse(
        status_code=400,
        content={
            "success": False,
            "error": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©",
            "message": str(exc),
            "timestamp": datetime.now().isoformat(),
            "request_id": generate_request_id()
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…"""
    ERROR_COUNT.labels(type='server_error').inc()
    logger.error(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": "Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…",
            "message": "Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹",
            "timestamp": datetime.now().isoformat(),
            "request_id": generate_request_id()
        }
    )

# ========================= ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù… =========================

if __name__ == "__main__":
    uvicorn.run(
        "sentiment_api:app",
        host="0.0.0.0",
        port=8001,
        reload=True,
        log_level="info",
        access_log=True
    )
