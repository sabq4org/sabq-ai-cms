# APIs Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙÙˆØ±ÙŠØ© ÙˆØ§Ù„Ù…Ø¬Ù…Ø¹Ø© - Ø³Ø¨Ù‚ Ø§Ù„Ø°ÙƒÙŠØ©
# Real-time and Batch Recommendation APIs

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, validator
from typing import Dict, List, Optional, Union, Any
from datetime import datetime, timedelta
from enum import Enum
import asyncio
import logging
import json
import time
import hashlib
from contextlib import asynccontextmanager
import uvicorn

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù†Ù…Ø§Ø°Ø¬ ML
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from models.collaborative_filtering import CollaborativeFilteringEnsemble
from models.content_based_filtering import ContentBasedRecommender
from models.hybrid_recommendation import HybridRecommendationEngine
from models.deep_learning_models import DeepRecommendationTrainer
from models.user_interest_analysis import UserInterestAnalysisEngine
from models.contextual_recommendations import ContextualRecommendationEngine
from models.continuous_learning import ContinuousLearningEngine

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ========================= Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª =========================

class RecommendationType(str, Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
    INSTANT = "instant"           # ÙÙˆØ±ÙŠØ©
    PERSONALIZED = "personalized" # Ø´Ø®ØµÙŠØ©
    TRENDING = "trending"         # Ø±Ø§Ø¦Ø¬Ø©
    SIMILAR = "similar"           # Ù…Ø´Ø§Ø¨Ù‡Ø©
    CONTEXTUAL = "contextual"     # Ø³ÙŠØ§Ù‚ÙŠØ©
    EXPLORE = "explore"           # Ø§Ø³ØªÙƒØ´Ø§ÙÙŠØ©

class InteractionType(str, Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„"""
    VIEW = "view"
    LIKE = "like"
    SAVE = "save"
    SHARE = "share"
    COMMENT = "comment"
    DISLIKE = "dislike"
    SKIP = "skip"

class UserContext(BaseModel):
    """Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    device_type: str = "mobile"
    location: Optional[Dict[str, str]] = None
    time_of_day: Optional[str] = None
    session_length: Optional[float] = None
    current_activity: Optional[str] = None
    mood_indicators: Optional[Dict[str, float]] = None

class RecommendationRequest(BaseModel):
    """Ø·Ù„Ø¨ ØªÙˆØµÙŠØ©"""
    user_id: str = Field(..., description="Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
    recommendation_type: RecommendationType = RecommendationType.PERSONALIZED
    count: int = Field(10, ge=1, le=100, description="Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª")
    context: Optional[UserContext] = None
    exclude_items: Optional[List[str]] = None
    filters: Optional[Dict[str, Any]] = None
    
    @validator('user_id')
    def validate_user_id(cls, v):
        if not v or len(v.strip()) == 0:
            raise ValueError('Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø·Ù„ÙˆØ¨')
        return v.strip()

class SimilarItemsRequest(BaseModel):
    """Ø·Ù„Ø¨ Ø¹Ù†Ø§ØµØ± Ù…Ø´Ø§Ø¨Ù‡Ø©"""
    item_id: str = Field(..., description="Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù‚Ø§Ù„")
    count: int = Field(10, ge=1, le=50)
    similarity_threshold: Optional[float] = Field(0.1, ge=0.0, le=1.0)

class BatchRecommendationRequest(BaseModel):
    """Ø·Ù„Ø¨ ØªÙˆØµÙŠØ§Øª Ù…Ø¬Ù…Ø¹Ø©"""
    user_ids: List[str] = Field(..., description="Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†")
    recommendation_type: RecommendationType = RecommendationType.PERSONALIZED
    count: int = Field(10, ge=1, le=50)
    context: Optional[UserContext] = None

class InteractionRequest(BaseModel):
    """Ø·Ù„Ø¨ ØªØ³Ø¬ÙŠÙ„ ØªÙØ§Ø¹Ù„"""
    user_id: str = Field(..., description="Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
    item_id: str = Field(..., description="Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù‚Ø§Ù„")
    interaction_type: InteractionType
    rating: Optional[float] = Field(None, ge=0.0, le=5.0)
    context: Optional[UserContext] = None
    timestamp: Optional[datetime] = None

class FeedbackRequest(BaseModel):
    """Ø·Ù„Ø¨ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø©"""
    user_id: str
    recommendation_id: str
    feedback_type: str = Field(..., description="Ù†ÙˆØ¹ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©")
    feedback_value: float = Field(..., ge=0.0, le=1.0)
    context: Optional[Dict[str, Any]] = None

class RecommendationItem(BaseModel):
    """Ø¹Ù†ØµØ± ØªÙˆØµÙŠØ©"""
    item_id: str
    score: float = Field(..., ge=0.0, le=1.0)
    reason: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None

class RecommendationResponse(BaseModel):
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„ØªÙˆØµÙŠØ©"""
    recommendations: List[RecommendationItem]
    total_count: int
    recommendation_id: str
    generated_at: datetime
    user_id: str
    recommendation_type: RecommendationType
    processing_time_ms: float
    metadata: Optional[Dict[str, Any]] = None

class BatchRecommendationResponse(BaseModel):
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©"""
    results: Dict[str, RecommendationResponse]
    total_users: int
    successful_recommendations: int
    failed_recommendations: int
    processing_time_ms: float
    generated_at: datetime

class AnalyticsResponse(BaseModel):
    """Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"""
    total_requests: int
    active_users: int
    popular_items: List[Dict[str, Any]]
    performance_metrics: Dict[str, float]
    system_health: Dict[str, Any]

# ========================= Ù…Ø¯ÙŠØ± Ø§Ù„Ø®Ø¯Ù…Ø§Øª =========================

class RecommendationServiceManager:
    """Ù…Ø¯ÙŠØ± Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
    
    def __init__(self):
        self.collaborative_model = None
        self.content_model = None
        self.hybrid_model = None
        self.deep_model = None
        self.interest_analyzer = None
        self.contextual_model = None
        self.continuous_learner = None
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.request_count = 0
        self.active_users = set()
        self.popular_items = {}
        self.response_times = []
        self.cache = {}
        self.cache_ttl = 300  # 5 Ø¯Ù‚Ø§Ø¦Ù‚
        
        # Ù‚ÙÙ„ Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
        self._lock = asyncio.Lock()
    
    async def initialize_models(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙˆØµÙŠØ§Øª...")
        
        try:
            # ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ Ù‡Ù†Ø§
            # Ù„Ù„ØªØ¨Ø³ÙŠØ·ØŒ Ø³Ù†Ø³ØªØ®Ø¯Ù… Ù†Ù…Ø§Ø°Ø¬ Ø¬Ø¯ÙŠØ¯Ø©
            
            # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø³ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡Ø§ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©)
            logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {str(e)}")
            raise
    
    async def get_recommendations(self, request: RecommendationRequest) -> RecommendationResponse:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙˆØµÙŠØ§Øª Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        start_time = time.time()
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.request_count += 1
        self.active_users.add(request.user_id)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
        cache_key = self._generate_cache_key(request)
        cached_result = await self._get_from_cache(cache_key)
        
        if cached_result:
            logger.info(f"ğŸ“¦ Ø¥Ø±Ø¬Ø§Ø¹ Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {request.user_id}")
            return cached_result
        
        try:
            # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØªÙˆØµÙŠØ© ÙˆØªÙ†ÙÙŠØ°Ù‡Ø§
            if request.recommendation_type == RecommendationType.INSTANT:
                recommendations = await self._get_instant_recommendations(request)
            elif request.recommendation_type == RecommendationType.PERSONALIZED:
                recommendations = await self._get_personalized_recommendations(request)
            elif request.recommendation_type == RecommendationType.TRENDING:
                recommendations = await self._get_trending_recommendations(request)
            elif request.recommendation_type == RecommendationType.CONTEXTUAL:
                recommendations = await self._get_contextual_recommendations(request)
            elif request.recommendation_type == RecommendationType.EXPLORE:
                recommendations = await self._get_exploratory_recommendations(request)
            else:
                recommendations = await self._get_similar_recommendations(request)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
            processing_time = (time.time() - start_time) * 1000
            self.response_times.append(processing_time)
            
            recommendation_id = self._generate_recommendation_id(request.user_id)
            
            response = RecommendationResponse(
                recommendations=recommendations,
                total_count=len(recommendations),
                recommendation_id=recommendation_id,
                generated_at=datetime.now(),
                user_id=request.user_id,
                recommendation_type=request.recommendation_type,
                processing_time_ms=processing_time,
                metadata={
                    "model_version": "1.0",
                    "cache_hit": False,
                    "filters_applied": request.filters is not None
                }
            )
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
            await self._save_to_cache(cache_key, response)
            
            logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(recommendations)} ØªÙˆØµÙŠØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {request.user_id}")
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {request.user_id}: {str(e)}")
            raise HTTPException(status_code=500, detail=f"ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {str(e)}")
    
    async def _get_instant_recommendations(self, request: RecommendationRequest) -> List[RecommendationItem]:
        """ØªÙˆØµÙŠØ§Øª ÙÙˆØ±ÙŠØ© Ø³Ø±ÙŠØ¹Ø©"""
        # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø¹Ø¨ÙŠØ© ÙˆØ§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø©
        recommendations = []
        
        # Ù…Ø­Ø§ÙƒØ§Ø© ØªÙˆØµÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©
        for i in range(min(request.count, 10)):
            item_id = f"trending_article_{i+1}"
            score = 0.9 - (i * 0.05)  # Ù†Ù‚Ø§Ø· Ù…ØªÙ†Ø§Ù‚ØµØ©
            
            recommendations.append(RecommendationItem(
                item_id=item_id,
                score=score,
                reason="Ù…Ù‚Ø§Ù„ Ø±Ø§Ø¦Ø¬ Ø­Ø§Ù„ÙŠØ§Ù‹",
                metadata={"type": "trending", "rank": i+1}
            ))
        
        return recommendations
    
    async def _get_personalized_recommendations(self, request: RecommendationRequest) -> List[RecommendationItem]:
        """ØªÙˆØµÙŠØ§Øª Ø´Ø®ØµÙŠØ©"""
        recommendations = []
        
        # Ù…Ø­Ø§ÙƒØ§Ø© ØªÙˆØµÙŠØ§Øª Ø´Ø®ØµÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        user_preferences = await self._get_user_preferences(request.user_id)
        
        for i in range(request.count):
            item_id = f"personal_article_{request.user_id}_{i+1}"
            base_score = 0.8
            
            # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            if user_preferences:
                preference_boost = user_preferences.get('engagement_level', 0.5) * 0.2
                base_score += preference_boost
            
            score = min(base_score - (i * 0.03), 1.0)
            
            recommendations.append(RecommendationItem(
                item_id=item_id,
                score=score,
                reason="Ù…Ø®ØµØµ Ù„Ø§Ù‡ØªÙ…Ø§Ù…Ø§ØªÙƒ",
                metadata={
                    "type": "personalized",
                    "user_profile_match": True,
                    "preference_score": user_preferences.get('main_interest_score', 0.5) if user_preferences else 0.5
                }
            ))
        
        return recommendations
    
    async def _get_trending_recommendations(self, request: RecommendationRequest) -> List[RecommendationItem]:
        """ØªÙˆØµÙŠØ§Øª Ø±Ø§Ø¦Ø¬Ø©"""
        recommendations = []
        
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ø±Ø§Ø¦Ø¬Ø©
        trending_topics = ["ØªÙ‚Ù†ÙŠØ©", "Ø³ÙŠØ§Ø³Ø©", "Ø±ÙŠØ§Ø¶Ø©", "Ø§Ù‚ØªØµØ§Ø¯", "ØµØ­Ø©"]
        
        for i in range(request.count):
            topic = trending_topics[i % len(trending_topics)]
            item_id = f"trending_{topic.lower()}_{i+1}"
            score = 0.95 - (i * 0.02)
            
            recommendations.append(RecommendationItem(
                item_id=item_id,
                score=score,
                reason=f"Ø±Ø§Ø¦Ø¬ ÙÙŠ {topic}",
                metadata={
                    "type": "trending",
                    "topic": topic,
                    "trend_score": score,
                    "viral_factor": 0.8
                }
            ))
        
        return recommendations
    
    async def _get_contextual_recommendations(self, request: RecommendationRequest) -> List[RecommendationItem]:
        """ØªÙˆØµÙŠØ§Øª Ø³ÙŠØ§Ù‚ÙŠØ©"""
        recommendations = []
        context = request.context
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚
        context_factors = {}
        if context:
            context_factors = {
                "device": context.device_type,
                "time": context.time_of_day,
                "activity": context.current_activity,
                "mood": context.mood_indicators
            }
        
        # Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
        for i in range(request.count):
            item_id = f"contextual_article_{i+1}"
            base_score = 0.75
            
            # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
            if context:
                if context.device_type == "mobile":
                    base_score += 0.1  # ØªÙØ¶ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„
                
                if context.current_activity == "commuting":
                    base_score += 0.05  # Ù…Ø­ØªÙˆÙ‰ Ù‚ØµÙŠØ± Ù„Ù„ØªÙ†Ù‚Ù„
                
                if context.mood_indicators:
                    mood_boost = sum(context.mood_indicators.values()) / len(context.mood_indicators) * 0.1
                    base_score += mood_boost
            
            score = min(base_score - (i * 0.02), 1.0)
            
            recommendations.append(RecommendationItem(
                item_id=item_id,
                score=score,
                reason="Ù…Ù†Ø§Ø³Ø¨ Ù„ÙˆØ¶Ø¹Ùƒ Ø§Ù„Ø­Ø§Ù„ÙŠ",
                metadata={
                    "type": "contextual",
                    "context_match": context_factors,
                    "context_score": score
                }
            ))
        
        return recommendations
    
    async def _get_exploratory_recommendations(self, request: RecommendationRequest) -> List[RecommendationItem]:
        """ØªÙˆØµÙŠØ§Øª Ø§Ø³ØªÙƒØ´Ø§ÙÙŠØ©"""
        recommendations = []
        
        # ØªÙˆØµÙŠØ§Øª Ù…ØªÙ†ÙˆØ¹Ø© Ù„Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
        diverse_categories = ["ÙÙ†", "Ø¹Ù„ÙˆÙ…", "Ø³ÙØ±", "Ø·Ø¨Ø®", "ØªØ§Ø±ÙŠØ®", "ÙÙ„Ø³ÙØ©", "ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§", "Ø·Ø¨ÙŠØ¹Ø©"]
        
        for i in range(request.count):
            category = diverse_categories[i % len(diverse_categories)]
            item_id = f"explore_{category.lower()}_{i+1}"
            score = 0.7 + (0.3 * (1 - i / request.count))  # Ù†Ù‚Ø§Ø· Ù…ØªØ¯Ø±Ø¬Ø©
            
            recommendations.append(RecommendationItem(
                item_id=item_id,
                score=score,
                reason=f"Ø§ÙƒØªØ´Ù {category}",
                metadata={
                    "type": "exploratory",
                    "category": category,
                    "novelty_score": 0.9,
                    "diversity_factor": True
                }
            ))
        
        return recommendations
    
    async def _get_similar_recommendations(self, request: RecommendationRequest) -> List[RecommendationItem]:
        """ØªÙˆØµÙŠØ§Øª Ù…Ø´Ø§Ø¨Ù‡Ø©"""
        recommendations = []
        
        # Ù…Ø­Ø§ÙƒØ§Ø© ØªÙˆØµÙŠØ§Øª Ù…Ø´Ø§Ø¨Ù‡Ø© (ÙŠØªØ·Ù„Ø¨ item_id ÙÙŠ Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ)
        for i in range(request.count):
            item_id = f"similar_article_{i+1}"
            score = 0.85 - (i * 0.04)
            
            recommendations.append(RecommendationItem(
                item_id=item_id,
                score=score,
                reason="Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù…Ø§ Ù‚Ø±Ø£ØªÙ‡",
                metadata={
                    "type": "similar",
                    "similarity_score": score,
                    "based_on": "user_history"
                }
            ))
        
        return recommendations
    
    async def get_similar_items(self, request: SimilarItemsRequest) -> List[RecommendationItem]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ù†Ø§ØµØ± Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù…Ù‚Ø§Ù„ Ù…Ø¹ÙŠÙ†"""
        recommendations = []
        
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù‚Ø§Ù„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø©
        for i in range(request.count):
            similar_item_id = f"similar_to_{request.item_id}_{i+1}"
            score = (request.similarity_threshold or 0.1) + (0.9 - 0.1) * (1 - i / request.count)
            
            recommendations.append(RecommendationItem(
                item_id=similar_item_id,
                score=score,
                reason=f"Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù„Ù…Ù‚Ø§Ù„ {request.item_id}",
                metadata={
                    "type": "content_similarity",
                    "base_item": request.item_id,
                    "similarity_method": "content_based"
                }
            ))
        
        logger.info(f"ğŸ” ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(recommendations)} Ù…Ù‚Ø§Ù„ Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù„Ù…Ù‚Ø§Ù„ {request.item_id}")
        
        return recommendations
    
    async def record_interaction(self, request: InteractionRequest) -> Dict[str, Any]:
        """ØªØ³Ø¬ÙŠÙ„ ØªÙØ§Ø¹Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        timestamp = request.timestamp or datetime.now()
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.active_users.add(request.user_id)
        
        if request.item_id not in self.popular_items:
            self.popular_items[request.item_id] = {"views": 0, "likes": 0, "saves": 0, "shares": 0}
        
        # ØªØ­Ø¯ÙŠØ« Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„
        if request.interaction_type == InteractionType.VIEW:
            self.popular_items[request.item_id]["views"] += 1
        elif request.interaction_type == InteractionType.LIKE:
            self.popular_items[request.item_id]["likes"] += 1
        elif request.interaction_type == InteractionType.SAVE:
            self.popular_items[request.item_id]["saves"] += 1
        elif request.interaction_type == InteractionType.SHARE:
            self.popular_items[request.item_id]["shares"] += 1
        
        # Ø¥Ø´Ø¹Ø§Ø± Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±
        if self.continuous_learner:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙØ§Ø¹Ù„ Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±
            pass
        
        logger.info(f"ğŸ“ ØªÙ… ØªØ³Ø¬ÙŠÙ„ ØªÙØ§Ø¹Ù„: {request.user_id} {request.interaction_type.value} {request.item_id}")
        
        return {
            "interaction_recorded": True,
            "user_id": request.user_id,
            "item_id": request.item_id,
            "interaction_type": request.interaction_type.value,
            "timestamp": timestamp.isoformat(),
            "processing_status": "success"
        }
    
    async def process_feedback(self, request: FeedbackRequest) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©"""
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©
        
        feedback_data = {
            "user_id": request.user_id,
            "recommendation_id": request.recommendation_id,
            "feedback_type": request.feedback_type,
            "feedback_value": request.feedback_value,
            "timestamp": datetime.now(),
            "context": request.context
        }
        
        # Ø¥Ø´Ø¹Ø§Ø± Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªØ¹Ù„Ù…
        if self.continuous_learner:
            # ØªÙ…Ø±ÙŠØ± Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±
            pass
        
        logger.info(f"ğŸ’­ ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ù…Ù† {request.user_id}: {request.feedback_type} = {request.feedback_value}")
        
        return {
            "feedback_processed": True,
            "recommendation_id": request.recommendation_id,
            "impact": "positive" if request.feedback_value > 0.5 else "negative",
            "learning_updated": True
        }
    
    async def get_batch_recommendations(self, request: BatchRecommendationRequest) -> BatchRecommendationResponse:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙˆØµÙŠØ§Øª Ù…Ø¬Ù…Ø¹Ø© Ù„Ø¹Ø¯Ø© Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
        start_time = time.time()
        results = {}
        successful = 0
        failed = 0
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ù…Ø³ØªØ®Ø¯Ù…
        for user_id in request.user_ids:
            try:
                individual_request = RecommendationRequest(
                    user_id=user_id,
                    recommendation_type=request.recommendation_type,
                    count=request.count,
                    context=request.context
                )
                
                user_recommendations = await self.get_recommendations(individual_request)
                results[user_id] = user_recommendations
                successful += 1
                
            except Exception as e:
                logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… {user_id}: {str(e)}")
                failed += 1
                continue
        
        processing_time = (time.time() - start_time) * 1000
        
        response = BatchRecommendationResponse(
            results=results,
            total_users=len(request.user_ids),
            successful_recommendations=successful,
            failed_recommendations=failed,
            processing_time_ms=processing_time,
            generated_at=datetime.now()
        )
        
        logger.info(f"ğŸ“¦ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…Ø¹Ø©: {successful} Ù†Ø¬Ø­ØŒ {failed} ÙØ´Ù„ Ù…Ù† {len(request.user_ids)} Ù…Ø³ØªØ®Ø¯Ù…")
        
        return response
    
    async def get_analytics(self) -> AnalyticsResponse:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´Ø¹Ø¨ÙŠØ©
        popular_items_list = []
        for item_id, stats in sorted(self.popular_items.items(), 
                                   key=lambda x: sum(x[1].values()), 
                                   reverse=True)[:10]:
            popular_items_list.append({
                "item_id": item_id,
                "total_interactions": sum(stats.values()),
                "breakdown": stats
            })
        
        # Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
        avg_response_time = sum(self.response_times[-100:]) / len(self.response_times[-100:]) if self.response_times else 0
        
        performance_metrics = {
            "average_response_time_ms": avg_response_time,
            "requests_per_minute": len(self.response_times[-60:]),  # ØªÙ‚Ø±ÙŠØ¨ÙŠ
            "cache_hit_rate": 0.3,  # Ù…Ø­Ø§ÙƒØ§Ø©
            "error_rate": 0.01,     # Ù…Ø­Ø§ÙƒØ§Ø©
            "throughput": self.request_count
        }
        
        # ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
        system_health = {
            "status": "healthy",
            "uptime_hours": 24,  # Ù…Ø­Ø§ÙƒØ§Ø©
            "memory_usage_percent": 65,
            "cpu_usage_percent": 45,
            "models_loaded": 6,
            "active_connections": len(self.active_users)
        }
        
        return AnalyticsResponse(
            total_requests=self.request_count,
            active_users=len(self.active_users),
            popular_items=popular_items_list,
            performance_metrics=performance_metrics,
            system_health=system_health
        )
    
    async def _get_user_preferences(self, user_id: str) -> Optional[Dict[str, Any]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø¬Ù„Ø¨ ØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        return {
            "main_interests": ["ØªÙ‚Ù†ÙŠØ©", "Ø³ÙŠØ§Ø³Ø©"],
            "engagement_level": 0.7,
            "main_interest_score": 0.8,
            "preferred_content_length": "medium",
            "preferred_time": "evening"
        }
    
    def _generate_cache_key(self, request: RecommendationRequest) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        key_data = f"{request.user_id}:{request.recommendation_type.value}:{request.count}"
        if request.context:
            key_data += f":{request.context.device_type}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    async def _get_from_cache(self, cache_key: str) -> Optional[RecommendationResponse]:
        """Ø¬Ù„Ø¨ Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        if cache_key in self.cache:
            cached_data, timestamp = self.cache[cache_key]
            if (datetime.now() - timestamp).total_seconds() < self.cache_ttl:
                return cached_data
            else:
                del self.cache[cache_key]
        return None
    
    async def _save_to_cache(self, cache_key: str, response: RecommendationResponse):
        """Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        self.cache[cache_key] = (response, datetime.now())
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ù‚Ø¯ÙŠÙ…
        if len(self.cache) > 1000:
            oldest_keys = sorted(self.cache.keys(), 
                               key=lambda k: self.cache[k][1])[:100]
            for key in oldest_keys:
                del self.cache[key]
    
    def _generate_recommendation_id(self, user_id: str) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±Ù ØªÙˆØµÙŠØ© ÙØ±ÙŠØ¯"""
        timestamp = int(time.time() * 1000)
        return f"rec_{user_id}_{timestamp}"

# ========================= Ø¥Ø¹Ø¯Ø§Ø¯ FastAPI =========================

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø§Ù„Ø®Ø¯Ù…Ø§Øª
service_manager = RecommendationServiceManager()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Ø¥Ø¯Ø§Ø±Ø© Ø¯ÙˆØ±Ø© Ø­ÙŠØ§Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"""
    # Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
    logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ·Ø¨ÙŠÙ‚ API Ø§Ù„ØªÙˆØµÙŠØ§Øª...")
    await service_manager.initialize_models()
    yield
    # Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
    logger.info("ğŸ”š Ø¥Ù†Ù‡Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚ API Ø§Ù„ØªÙˆØµÙŠØ§Øª...")

# Ø¥Ù†Ø´Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚ FastAPI
app = FastAPI(
    title="Sabq AI Recommendation API",
    description="API Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠ Ù„Ø³Ø¨Ù‚ Ø§Ù„Ø°ÙƒÙŠØ©",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# Ø¥Ø¹Ø¯Ø§Ø¯ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========================= Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§ÙŠØ© =========================

@app.get("/", tags=["Ø¹Ø§Ù…"])
async def root():
    """Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ© Ø¬Ø°Ø±"""
    return {
        "message": "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ API Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠØ© - Ø³Ø¨Ù‚ Ø§Ù„Ø°ÙƒÙŠØ©",
        "version": "1.0.0",
        "status": "active",
        "docs": "/docs"
    }

@app.get("/health", tags=["Ø¹Ø§Ù…"])
async def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "system": "recommendation_api",
        "version": "1.0.0"
    }

@app.post("/recommendations", response_model=RecommendationResponse, tags=["Ø§Ù„ØªÙˆØµÙŠØ§Øª"])
async def get_recommendations(request: RecommendationRequest):
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙˆØµÙŠØ§Øª Ù…Ø®ØµØµØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
    
    - **user_id**: Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù…Ø·Ù„ÙˆØ¨)
    - **recommendation_type**: Ù†ÙˆØ¹ Ø§Ù„ØªÙˆØµÙŠØ©
    - **count**: Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª (1-100)
    - **context**: Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
    - **exclude_items**: Ù…Ù‚Ø§Ù„Ø§Øª Ù„Ù„Ø§Ø³ØªØ¨Ø¹Ø§Ø¯
    - **filters**: Ù…Ø±Ø´Ø­Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    """
    return await service_manager.get_recommendations(request)

@app.post("/recommendations/similar", response_model=List[RecommendationItem], tags=["Ø§Ù„ØªÙˆØµÙŠØ§Øª"])
async def get_similar_items(request: SimilarItemsRequest):
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù‚Ø§Ù„Ø§Øª Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù…Ù‚Ø§Ù„ Ù…Ø¹ÙŠÙ†
    
    - **item_id**: Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù‚Ø§Ù„ (Ù…Ø·Ù„ÙˆØ¨)
    - **count**: Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©
    - **similarity_threshold**: Ø­Ø¯ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£Ø¯Ù†Ù‰
    """
    return await service_manager.get_similar_items(request)

@app.post("/recommendations/batch", response_model=BatchRecommendationResponse, tags=["Ø§Ù„ØªÙˆØµÙŠØ§Øª"])
async def get_batch_recommendations(request: BatchRecommendationRequest):
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙˆØµÙŠØ§Øª Ù…Ø¬Ù…Ø¹Ø© Ù„Ø¹Ø¯Ø© Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
    
    - **user_ids**: Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
    - **recommendation_type**: Ù†ÙˆØ¹ Ø§Ù„ØªÙˆØµÙŠØ©
    - **count**: Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù„ÙƒÙ„ Ù…Ø³ØªØ®Ø¯Ù…
    """
    return await service_manager.get_batch_recommendations(request)

@app.post("/interactions", tags=["Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª"])
async def record_interaction(request: InteractionRequest):
    """
    ØªØ³Ø¬ÙŠÙ„ ØªÙØ§Ø¹Ù„ Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ Ù…Ù‚Ø§Ù„
    
    - **user_id**: Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    - **item_id**: Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù‚Ø§Ù„
    - **interaction_type**: Ù†ÙˆØ¹ Ø§Ù„ØªÙØ§Ø¹Ù„
    - **rating**: ØªÙ‚ÙŠÙŠÙ… Ø§Ø®ØªÙŠØ§Ø±ÙŠ (0-5)
    - **context**: Ø³ÙŠØ§Ù‚ Ø§Ù„ØªÙØ§Ø¹Ù„
    """
    return await service_manager.record_interaction(request)

@app.post("/feedback", tags=["Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©"])
async def submit_feedback(request: FeedbackRequest):
    """
    Ø¥Ø±Ø³Ø§Ù„ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ø­ÙˆÙ„ Ø§Ù„ØªÙˆØµÙŠØ§Øª
    
    - **user_id**: Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    - **recommendation_id**: Ù…Ø¹Ø±Ù Ø§Ù„ØªÙˆØµÙŠØ©
    - **feedback_type**: Ù†ÙˆØ¹ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
    - **feedback_value**: Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© (0-1)
    """
    return await service_manager.process_feedback(request)

@app.get("/analytics", response_model=AnalyticsResponse, tags=["Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"])
async def get_analytics():
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„Ø§Øª ÙˆØ¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    
    ÙŠØªØ¶Ù…Ù†:
    - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
    - Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù†Ø´Ø·ÙŠÙ†
    - Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´Ø¹Ø¨ÙŠØ©
    - Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
    - ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    """
    return await service_manager.get_analytics()

@app.get("/users/{user_id}/profile", tags=["Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"])
async def get_user_profile(user_id: str):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØªÙØ¶ÙŠÙ„Ø§ØªÙ‡"""
    user_preferences = await service_manager._get_user_preferences(user_id)
    return {
        "user_id": user_id,
        "preferences": user_preferences,
        "last_activity": datetime.now().isoformat(),
        "recommendation_history_count": 42  # Ù…Ø­Ø§ÙƒØ§Ø©
    }

@app.get("/items/{item_id}/stats", tags=["Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª"])
async def get_item_stats(item_id: str):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…Ù‚Ø§Ù„"""
    stats = service_manager.popular_items.get(item_id, {
        "views": 0, "likes": 0, "saves": 0, "shares": 0
    })
    
    return {
        "item_id": item_id,
        "statistics": stats,
        "total_interactions": sum(stats.values()),
        "popularity_score": sum(stats.values()) / 100,  # ØªØ·Ø¨ÙŠØ¹
        "last_updated": datetime.now().isoformat()
    }

@app.get("/trending", tags=["Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª"])
async def get_trending_content(
    limit: int = Query(10, ge=1, le=50, description="Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø±Ø§Ø¦Ø¬Ø©"),
    time_window: str = Query("24h", description="Ø§Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© (1h, 24h, 7d)")
):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø§Ø¦Ø¬"""
    
    # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø§Ø¦Ø¬
    trending_items = []
    for i in range(limit):
        trending_items.append({
            "item_id": f"trending_item_{i+1}",
            "title": f"Ù…Ù‚Ø§Ù„ Ø±Ø§Ø¦Ø¬ #{i+1}",
            "trend_score": 0.9 - (i * 0.05),
            "category": ["ØªÙ‚Ù†ÙŠØ©", "Ø³ÙŠØ§Ø³Ø©", "Ø±ÙŠØ§Ø¶Ø©", "Ø§Ù‚ØªØµØ§Ø¯"][i % 4],
            "interactions_count": 1000 - (i * 50),
            "growth_rate": f"+{150 - i*10}%"
        })
    
    return {
        "trending_items": trending_items,
        "time_window": time_window,
        "generated_at": datetime.now().isoformat(),
        "total_items": limit
    }

# ========================= Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ =========================

@app.exception_handler(ValueError)
async def value_error_handler(request, exc):
    """Ù…Ø¹Ø§Ù„Ø¬ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù‚ÙŠÙ…"""
    return JSONResponse(
        status_code=400,
        content={
            "error": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©",
            "message": str(exc),
            "timestamp": datetime.now().isoformat()
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…"""
    logger.error(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…",
            "message": "Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹",
            "timestamp": datetime.now().isoformat()
        }
    )

# ========================= ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù… =========================

if __name__ == "__main__":
    uvicorn.run(
        "recommendation_routes:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
