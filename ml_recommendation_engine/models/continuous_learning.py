# Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù…Ù† Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª - Ø³Ø¨Ù‚ Ø§Ù„Ø°ÙƒÙŠØ©
# Continuous Learning System from User Interactions

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, mean_squared_error
from sklearn.model_selection import train_test_split
import logging
from typing import Dict, List, Tuple, Optional, Any, Union, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from collections import defaultdict, deque
from enum import Enum
import json
import joblib
import pickle
import asyncio
from concurrent.futures import ThreadPoolExecutor
import threading
import time
import math
import random
from abc import ABC, abstractmethod

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LearningStrategy(Enum):
    """Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…"""
    ONLINE = "online"           # ØªØ¹Ù„Ù… Ù…Ø¨Ø§Ø´Ø± Ù…Ù† ÙƒÙ„ ØªÙØ§Ø¹Ù„
    BATCH = "batch"            # ØªØ¹Ù„Ù… Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    MINI_BATCH = "mini_batch"  # ØªØ¹Ù„Ù… Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ØµØºÙŠØ±Ø©
    FEDERATED = "federated"    # ØªØ¹Ù„Ù… Ù…ÙˆØ²Ø¹
    ACTIVE = "active"          # ØªØ¹Ù„Ù… Ù†Ø´Ø· Ù…Ø¹ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª
    REINFORCEMENT = "reinforcement"  # ØªØ¹Ù„Ù… ØªØ¹Ø²ÙŠØ²ÙŠ

class ConceptDriftType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…ÙŠ"""
    SUDDEN = "sudden"          # ØªØºÙŠÙŠØ± Ù…ÙØ§Ø¬Ø¦
    GRADUAL = "gradual"        # ØªØºÙŠÙŠØ± ØªØ¯Ø±ÙŠØ¬ÙŠ
    INCREMENTAL = "incremental"  # ØªØºÙŠÙŠØ± Ù…ØªØ²Ø§ÙŠØ¯
    RECURRING = "recurring"    # ØªØºÙŠÙŠØ± Ø¯ÙˆØ±ÙŠ
    VIRTUAL = "virtual"        # ØªØºÙŠÙŠØ± ÙˆÙ‡Ù…ÙŠ

@dataclass
class LearningConfig:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±"""
    # Learning strategy
    strategy: LearningStrategy = LearningStrategy.MINI_BATCH
    learning_rate: float = 0.001
    batch_size: int = 32
    update_frequency: int = 100  # Ø¹Ø¯Ø¯ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ«
    
    # Memory management
    memory_size: int = 10000
    forgetting_rate: float = 0.95
    importance_threshold: float = 0.1
    
    # Concept drift detection
    drift_detection_window: int = 1000
    drift_threshold: float = 0.05
    drift_adaptation_rate: float = 0.1
    
    # Performance monitoring
    performance_window: int = 500
    min_performance_threshold: float = 0.6
    performance_degradation_threshold: float = 0.1
    
    # Model management
    model_ensemble_size: int = 5
    model_retirement_threshold: float = 0.3
    new_model_promotion_threshold: float = 0.8
    
    # Online learning
    online_learning_enabled: bool = True
    regularization_strength: float = 0.01
    momentum: float = 0.9
    
    # Active learning
    uncertainty_threshold: float = 0.7
    query_budget: int = 100
    acquisition_function: str = "uncertainty"  # uncertainty, diversity, expected_improvement

@dataclass
class InteractionRecord:
    """Ø³Ø¬Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„"""
    user_id: str
    item_id: str
    interaction_type: str
    rating: float
    context: Dict[str, Any]
    features: Optional[np.ndarray] = None
    prediction: Optional[float] = None
    timestamp: datetime = field(default_factory=datetime.now)
    importance_weight: float = 1.0
    is_labeled: bool = True


class ExperienceReplay:
    """
    Ø°Ø§ÙƒØ±Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±
    Experience Replay Memory for Continuous Learning
    """
    
    def __init__(self, config: LearningConfig):
        self.config = config
        self.memory = deque(maxlen=config.memory_size)
        self.importance_weights = deque(maxlen=config.memory_size)
        self.temporal_weights = deque(maxlen=config.memory_size)
        
    def store_interaction(self, interaction: InteractionRecord):
        """Ø­ÙØ¸ ØªÙØ§Ø¹Ù„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        # Ø­Ø³Ø§Ø¨ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªÙØ§Ø¹Ù„
        importance = self._calculate_importance(interaction)
        temporal_weight = 1.0  # ÙˆØ²Ù† Ø²Ù…Ù†ÙŠ ÙƒØ§Ù…Ù„ Ù„Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        
        self.memory.append(interaction)
        self.importance_weights.append(importance)
        self.temporal_weights.append(temporal_weight)
        
        # ØªØ·Ø¨ÙŠÙ‚ ØªØ±Ø§Ø¬Ø¹ Ø²Ù…Ù†ÙŠ Ù„Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        self._apply_temporal_decay()
    
    def _calculate_importance(self, interaction: InteractionRecord) -> float:
        """Ø­Ø³Ø§Ø¨ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªÙØ§Ø¹Ù„"""
        importance = 1.0
        
        # Ø£Ù‡Ù…ÙŠØ© Ù†ÙˆØ¹ Ø§Ù„ØªÙØ§Ø¹Ù„
        interaction_weights = {
            'view': 0.5,
            'like': 1.0,
            'save': 1.2,
            'share': 1.5,
            'comment': 1.3,
            'dislike': 0.8,
            'skip': 0.3
        }
        
        importance *= interaction_weights.get(interaction.interaction_type, 1.0)
        
        # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        if interaction.rating > 0:
            importance *= (1 + interaction.rating / 5.0)
        
        # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø³ÙŠØ§Ù‚
        if interaction.context:
            # ØªÙØ§Ø¹Ù„Ø§Øª ÙÙŠ Ø³ÙŠØ§Ù‚Ø§Øª Ù†Ø§Ø¯Ø±Ø© Ø£ÙƒØ«Ø± Ø£Ù‡Ù…ÙŠØ©
            context_rarity = len(interaction.context) / 10.0  # ØªØ·Ø¨ÙŠØ¹
            importance *= (1 + context_rarity)
        
        return min(importance, 3.0)  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ø£Ù‡Ù…ÙŠØ©
    
    def _apply_temporal_decay(self):
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ±Ø§Ø¬Ø¹ Ø²Ù…Ù†ÙŠ"""
        for i in range(len(self.temporal_weights)):
            self.temporal_weights[i] *= self.config.forgetting_rate
    
    def sample_batch(self, batch_size: int, strategy: str = "importance") -> List[InteractionRecord]:
        """Ø³Ø­Ø¨ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        if len(self.memory) < batch_size:
            return list(self.memory)
        
        if strategy == "importance":
            # Ø§Ù„Ø¹ÙŠÙ†Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©
            weights = np.array(self.importance_weights) * np.array(self.temporal_weights)
            weights = weights / weights.sum()  # ØªØ·Ø¨ÙŠØ¹
            
            indices = np.random.choice(
                len(self.memory), 
                size=batch_size, 
                replace=False, 
                p=weights
            )
            
        elif strategy == "recent":
            # Ø£Ø­Ø¯Ø« Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª
            indices = list(range(max(0, len(self.memory) - batch_size), len(self.memory)))
            
        elif strategy == "diverse":
            # Ø¹ÙŠÙ†Ø© Ù…ØªÙ†ÙˆØ¹Ø©
            indices = self._diverse_sampling(batch_size)
            
        else:  # random
            indices = random.sample(range(len(self.memory)), batch_size)
        
        return [self.memory[i] for i in indices]
    
    def _diverse_sampling(self, batch_size: int) -> List[int]:
        """Ø¹ÙŠÙ†Ø© Ù…ØªÙ†ÙˆØ¹Ø© Ù…Ù† Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª"""
        # ØªÙ†ÙÙŠØ° Ù…Ø¨Ø³Ø· Ù„Ù„ØªÙ†ÙˆÙŠØ¹
        # ÙŠÙ…ÙƒÙ† ØªØ·ÙˆÙŠØ±Ù‡ Ù„ÙŠØ´Ù…Ù„ ØªÙ†ÙˆÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ø§Ù„Ù†ÙˆØ¹ØŒ Ø§Ù„Ø³ÙŠØ§Ù‚
        
        user_interactions = defaultdict(list)
        for i, interaction in enumerate(self.memory):
            user_interactions[interaction.user_id].append(i)
        
        selected_indices = []
        
        # Ø§Ø®ØªÙŠØ§Ø± ØªÙØ§Ø¹Ù„ ÙˆØ§Ø­Ø¯ Ù…Ù† ÙƒÙ„ Ù…Ø³ØªØ®Ø¯Ù… Ø£ÙˆÙ„Ø§Ù‹
        for user_id, indices in user_interactions.items():
            if len(selected_indices) < batch_size:
                selected_indices.append(random.choice(indices))
        
        # Ù…Ù„Ø¡ Ø§Ù„Ø¨Ø§Ù‚ÙŠ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ§Ù‹
        remaining = batch_size - len(selected_indices)
        if remaining > 0:
            all_indices = set(range(len(self.memory)))
            available_indices = list(all_indices - set(selected_indices))
            if available_indices:
                selected_indices.extend(
                    random.sample(available_indices, min(remaining, len(available_indices)))
                )
        
        return selected_indices[:batch_size]
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        if not self.memory:
            return {}
        
        interaction_types = defaultdict(int)
        user_counts = defaultdict(int)
        
        for interaction in self.memory:
            interaction_types[interaction.interaction_type] += 1
            user_counts[interaction.user_id] += 1
        
        return {
            'total_interactions': len(self.memory),
            'unique_users': len(user_counts),
            'interaction_distribution': dict(interaction_types),
            'average_importance': np.mean(self.importance_weights),
            'average_temporal_weight': np.mean(self.temporal_weights),
            'memory_utilization': len(self.memory) / self.config.memory_size
        }


class ConceptDriftDetector:
    """
    ÙƒØ§Ø´Ù Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…ÙŠ
    Concept Drift Detector
    """
    
    def __init__(self, config: LearningConfig):
        self.config = config
        self.performance_history = deque(maxlen=config.drift_detection_window)
        self.prediction_history = deque(maxlen=config.drift_detection_window)
        self.feature_statistics = defaultdict(lambda: deque(maxlen=config.drift_detection_window))
        self.drift_alerts = []
        
    def update_performance(self, accuracy: float, predictions: List[float], 
                         features: Optional[np.ndarray] = None):
        """ØªØ­Ø¯ÙŠØ« Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        self.performance_history.append({
            'accuracy': accuracy,
            'timestamp': datetime.now()
        })
        
        self.prediction_history.extend(predictions)
        
        # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ù…
        if features is not None:
            for i, feature_values in enumerate(features.T):
                self.feature_statistics[f'feature_{i}'].extend(feature_values)
    
    def detect_drift(self) -> Tuple[bool, ConceptDriftType, float]:
        """ÙƒØ´Ù Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…ÙŠ"""
        if len(self.performance_history) < 50:
            return False, ConceptDriftType.VIRTUAL, 0.0
        
        # ÙƒØ´Ù Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ø£Ø¯Ø§Ø¡
        performance_drift = self._detect_performance_drift()
        
        # ÙƒØ´Ù Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data_drift = self._detect_data_drift()
        
        # ÙƒØ´Ù Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
        prediction_drift = self._detect_prediction_drift()
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù ÙˆØ´Ø¯ØªÙ‡
        total_drift = max(performance_drift, data_drift, prediction_drift)
        
        if total_drift > self.config.drift_threshold:
            drift_type = self._classify_drift_type()
            
            # ØªØ³Ø¬ÙŠÙ„ ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù
            self.drift_alerts.append({
                'timestamp': datetime.now(),
                'drift_type': drift_type,
                'severity': total_drift,
                'components': {
                    'performance': performance_drift,
                    'data': data_drift,
                    'prediction': prediction_drift
                }
            })
            
            logger.warning(f"âš ï¸ ØªÙ… ÙƒØ´Ù Ø§Ù†Ø­Ø±Ø§Ù Ù…ÙØ§Ù‡ÙŠÙ…ÙŠ: {drift_type.value} (Ø´Ø¯Ø©: {total_drift:.3f})")
            
            return True, drift_type, total_drift
        
        return False, ConceptDriftType.VIRTUAL, total_drift
    
    def _detect_performance_drift(self) -> float:
        """ÙƒØ´Ù Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        if len(self.performance_history) < 20:
            return 0.0
        
        recent_performance = [p['accuracy'] for p in list(self.performance_history)[-10:]]
        older_performance = [p['accuracy'] for p in list(self.performance_history)[-20:-10]]
        
        recent_avg = np.mean(recent_performance)
        older_avg = np.mean(older_performance)
        
        performance_drop = older_avg - recent_avg
        return max(0, performance_drop)
    
    def _detect_data_drift(self) -> float:
        """ÙƒØ´Ù Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if not self.feature_statistics:
            return 0.0
        
        drift_scores = []
        
        for feature_name, feature_values in self.feature_statistics.items():
            if len(feature_values) < 100:
                continue
            
            # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ù…Ø¹ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            recent_values = list(feature_values)[-50:]
            older_values = list(feature_values)[-100:-50]
            
            # Ø§Ø®ØªØ¨Ø§Ø± Kolmogorov-Smirnov Ø§Ù„Ù…Ø¨Ø³Ø·
            drift_score = self._ks_test_approximation(recent_values, older_values)
            drift_scores.append(drift_score)
        
        return np.mean(drift_scores) if drift_scores else 0.0
    
    def _detect_prediction_drift(self) -> float:
        """ÙƒØ´Ù Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª"""
        if len(self.prediction_history) < 100:
            return 0.0
        
        predictions = list(self.prediction_history)
        recent_predictions = predictions[-50:]
        older_predictions = predictions[-100:-50]
        
        # Ù…Ù‚Ø§Ø±Ù†Ø© ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
        recent_mean = np.mean(recent_predictions)
        older_mean = np.mean(older_predictions)
        
        recent_std = np.std(recent_predictions)
        older_std = np.std(older_predictions)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø®ØªÙ„Ø§Ù ÙÙŠ Ø§Ù„Ù…ØªÙˆØ³Ø· ÙˆØ§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ
        mean_drift = abs(recent_mean - older_mean)
        std_drift = abs(recent_std - older_std)
        
        return (mean_drift + std_drift) / 2
    
    def _ks_test_approximation(self, sample1: List[float], sample2: List[float]) -> float:
        """ØªÙ‚Ø±ÙŠØ¨ Ø§Ø®ØªØ¨Ø§Ø± Kolmogorov-Smirnov"""
        if not sample1 or not sample2:
            return 0.0
        
        # ØªÙ‚Ø±ÙŠØ¨ Ù…Ø¨Ø³Ø· Ù„Ø­Ø³Ø§Ø¨ Ø§Ø®ØªÙ„Ø§Ù Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª
        mean_diff = abs(np.mean(sample1) - np.mean(sample2))
        std_diff = abs(np.std(sample1) - np.std(sample2))
        
        # ØªØ·Ø¨ÙŠØ¹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ…
        mean_norm = mean_diff / (abs(np.mean(sample1)) + abs(np.mean(sample2)) + 1e-6)
        std_norm = std_diff / (np.std(sample1) + np.std(sample2) + 1e-6)
        
        return (mean_norm + std_norm) / 2
    
    def _classify_drift_type(self) -> ConceptDriftType:
        """ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù"""
        if len(self.drift_alerts) < 2:
            return ConceptDriftType.SUDDEN
        
        # ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù
        recent_alerts = self.drift_alerts[-5:]
        time_gaps = []
        
        for i in range(1, len(recent_alerts)):
            gap = (recent_alerts[i]['timestamp'] - recent_alerts[i-1]['timestamp']).total_seconds()
            time_gaps.append(gap)
        
        if not time_gaps:
            return ConceptDriftType.SUDDEN
        
        avg_gap = np.mean(time_gaps)
        gap_variance = np.var(time_gaps)
        
        # ØªØµÙ†ÙŠÙ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø²Ù…Ù†ÙŠØ©
        if avg_gap < 3600:  # Ø£Ù‚Ù„ Ù…Ù† Ø³Ø§Ø¹Ø©
            return ConceptDriftType.SUDDEN
        elif gap_variance < avg_gap * 0.1:  # Ø§Ù†ØªØ¸Ø§Ù… Ø¹Ø§Ù„ÙŠ
            return ConceptDriftType.RECURRING
        elif avg_gap > 86400:  # Ø£ÙƒØ«Ø± Ù…Ù† ÙŠÙˆÙ…
            return ConceptDriftType.GRADUAL
        else:
            return ConceptDriftType.INCREMENTAL
    
    def get_drift_summary(self) -> Dict[str, Any]:
        """Ù…Ù„Ø®Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù"""
        return {
            'total_alerts': len(self.drift_alerts),
            'recent_alerts': len([a for a in self.drift_alerts 
                                if (datetime.now() - a['timestamp']).days <= 7]),
            'drift_types_distribution': self._get_drift_type_distribution(),
            'average_severity': np.mean([a['severity'] for a in self.drift_alerts]) if self.drift_alerts else 0,
            'last_drift': self.drift_alerts[-1] if self.drift_alerts else None
        }
    
    def _get_drift_type_distribution(self) -> Dict[str, int]:
        """ØªÙˆØ²ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù"""
        distribution = defaultdict(int)
        for alert in self.drift_alerts:
            distribution[alert['drift_type'].value] += 1
        return dict(distribution)


class OnlineLearner:
    """
    Ù…ØªØ¹Ù„Ù… Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ù†Ù…Ø§Ø°Ø¬
    Online Learner for Models
    """
    
    def __init__(self, model: nn.Module, config: LearningConfig):
        self.model = model
        self.config = config
        self.optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)
        self.criterion = nn.MSELoss()
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…
        self.update_count = 0
        self.cumulative_loss = 0.0
        self.learning_history = deque(maxlen=1000)
        
    def update_model(self, batch_interactions: List[InteractionRecord]) -> Dict[str, float]:
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙØ§Ø¹Ù„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©"""
        if not batch_interactions:
            return {}
        
        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        features, targets, weights = self._prepare_batch_data(batch_interactions)
        
        if len(features) == 0:
            return {}
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ tensors
        X = torch.FloatTensor(features)
        y = torch.FloatTensor(targets)
        w = torch.FloatTensor(weights)
        
        # Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        self.model.train()
        self.optimizer.zero_grad()
        
        predictions = self.model(X).squeeze()
        loss = self._weighted_loss(predictions, y, w)
        
        loss.backward()
        self.optimizer.step()
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.update_count += 1
        self.cumulative_loss += loss.item()
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        with torch.no_grad():
            mse = nn.MSELoss()(predictions, y).item()
            mae = torch.mean(torch.abs(predictions - y)).item()
        
        # Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ¹Ù„Ù…
        learning_record = {
            'timestamp': datetime.now(),
            'loss': loss.item(),
            'mse': mse,
            'mae': mae,
            'batch_size': len(batch_interactions),
            'learning_rate': self.optimizer.param_groups[0]['lr']
        }
        
        self.learning_history.append(learning_record)
        
        logger.info(f"ğŸ“š ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - Loss: {loss.item():.4f}, MAE: {mae:.4f}")
        
        return {
            'loss': loss.item(),
            'mse': mse,
            'mae': mae,
            'updates_count': self.update_count
        }
    
    def _prepare_batch_data(self, interactions: List[InteractionRecord]) -> Tuple[List, List, List]:
        """ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯ÙØ¹Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        features = []
        targets = []
        weights = []
        
        for interaction in interactions:
            if interaction.features is not None and interaction.is_labeled:
                features.append(interaction.features)
                targets.append(interaction.rating)
                weights.append(interaction.importance_weight)
        
        return features, targets, weights
    
    def _weighted_loss(self, predictions: torch.Tensor, 
                      targets: torch.Tensor, 
                      weights: torch.Tensor) -> torch.Tensor:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù…Ø±Ø¬Ø­Ø©"""
        mse_loss = (predictions - targets) ** 2
        weighted_loss = torch.mean(mse_loss * weights)
        
        # Ø¥Ø¶Ø§ÙØ© ØªÙ†Ø¸ÙŠÙ…
        l2_reg = sum(p.pow(2.0).sum() for p in self.model.parameters())
        total_loss = weighted_loss + self.config.regularization_strength * l2_reg
        
        return total_loss
    
    def adapt_learning_rate(self, performance_trend: float):
        """ØªÙƒÙŠÙŠÙ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        current_lr = self.optimizer.param_groups[0]['lr']
        
        if performance_trend > 0.05:  # ØªØ­Ø³Ù† ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡
            new_lr = min(current_lr * 1.1, 0.01)
        elif performance_trend < -0.05:  # ØªØ±Ø§Ø¬Ø¹ ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡
            new_lr = max(current_lr * 0.9, 1e-5)
        else:
            new_lr = current_lr
        
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = new_lr
        
        if new_lr != current_lr:
            logger.info(f"ğŸ¯ ØªØ¹Ø¯ÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…: {current_lr:.6f} â†’ {new_lr:.6f}")
    
    def get_learning_statistics(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…"""
        if not self.learning_history:
            return {}
        
        recent_history = list(self.learning_history)[-100:]
        
        return {
            'total_updates': self.update_count,
            'average_loss': self.cumulative_loss / max(self.update_count, 1),
            'recent_average_loss': np.mean([h['loss'] for h in recent_history]),
            'recent_average_mae': np.mean([h['mae'] for h in recent_history]),
            'current_learning_rate': self.optimizer.param_groups[0]['lr'],
            'learning_trend': self._calculate_learning_trend()
        }
    
    def _calculate_learning_trend(self) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªØ¹Ù„Ù…"""
        if len(self.learning_history) < 10:
            return 0.0
        
        recent_losses = [h['loss'] for h in list(self.learning_history)[-10:]]
        older_losses = [h['loss'] for h in list(self.learning_history)[-20:-10]]
        
        if not older_losses:
            return 0.0
        
        recent_avg = np.mean(recent_losses)
        older_avg = np.mean(older_losses)
        
        # Ø§ØªØ¬Ø§Ù‡ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ ÙŠØ¹Ù†ÙŠ ØªØ­Ø³Ù† (Ø®Ø³Ø§Ø±Ø© Ø£Ù‚Ù„)
        return older_avg - recent_avg


class ActiveLearner:
    """
    Ù…ØªØ¹Ù„Ù… Ù†Ø´Ø· Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
    Active Learner for Querying Important Data
    """
    
    def __init__(self, config: LearningConfig):
        self.config = config
        self.query_budget = config.query_budget
        self.queries_made = 0
        self.uncertain_samples = deque(maxlen=1000)
        
    def should_query(self, interaction: InteractionRecord) -> bool:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„ØªÙØ§Ø¹Ù„"""
        if self.queries_made >= self.query_budget:
            return False
        
        if interaction.prediction is None:
            return False
        
        # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ†
        uncertainty = self._calculate_uncertainty(interaction)
        
        if uncertainty > self.config.uncertainty_threshold:
            self.uncertain_samples.append({
                'interaction': interaction,
                'uncertainty': uncertainty,
                'timestamp': datetime.now()
            })
            
            # Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
            if self.config.acquisition_function == "uncertainty":
                return True
            elif self.config.acquisition_function == "diversity":
                return self._is_diverse_sample(interaction)
            elif self.config.acquisition_function == "expected_improvement":
                return self._has_expected_improvement(interaction)
        
        return False
    
    def _calculate_uncertainty(self, interaction: InteractionRecord) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ† ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤"""
        if interaction.prediction is None:
            return 0.0
        
        # Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø³Ø§ÙØ© Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ù† Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
        # (ØªÙ†ÙÙŠØ° Ù…Ø¨Ø³Ø· - ÙŠÙ…ÙƒÙ† ØªØ·ÙˆÙŠØ±Ù‡)
        
        prediction = interaction.prediction
        
        # Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ† Ø£ÙƒØ¨Ø± ÙƒÙ„Ù…Ø§ Ø§Ù‚ØªØ±Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ù† 0.5 (ÙÙŠ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ)
        # Ø£Ùˆ ÙƒÙ„Ù…Ø§ ÙƒØ§Ù† Ø§Ù„ØªÙ†Ø¨Ø¤ ÙÙŠ Ù…Ù†Ø·Ù‚Ø© ØºÙŠØ± Ù…Ø¤ÙƒØ¯Ø©
        
        if 0 <= prediction <= 1:  # ØªØ·Ø¨ÙŠØ¹ Ù„Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª
            uncertainty = 1 - abs(prediction - 0.5) * 2
        else:  # Ù„Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ø·Ø¨Ø¹Ø©
            uncertainty = 1 / (1 + abs(prediction))
        
        return uncertainty
    
    def _is_diverse_sample(self, interaction: InteractionRecord) -> bool:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¹ÙŠÙ†Ø© Ù…ØªÙ†ÙˆØ¹Ø©"""
        if not self.uncertain_samples:
            return True
        
        # Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© Ù„Ù„ØªÙ†ÙˆØ¹
        current_features = interaction.features
        if current_features is None:
            return False
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ø¹ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
        similarities = []
        for sample in list(self.uncertain_samples)[-10:]:  # Ø¢Ø®Ø± 10 Ø¹ÙŠÙ†Ø§Øª
            other_features = sample['interaction'].features
            if other_features is not None:
                similarity = np.dot(current_features, other_features) / (
                    np.linalg.norm(current_features) * np.linalg.norm(other_features) + 1e-6
                )
                similarities.append(similarity)
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ù†Ø®ÙØ¶ Ù…Ø¹ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ ÙÙ‡ÙŠ Ù…ØªÙ†ÙˆØ¹Ø©
        avg_similarity = np.mean(similarities) if similarities else 0
        return avg_similarity < 0.7
    
    def _has_expected_improvement(self, interaction: InteractionRecord) -> bool:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¹ÙŠÙ†Ø© ØªØ¹Ø¯ Ø¨ØªØ­Ø³Ù† Ù…ØªÙˆÙ‚Ø¹"""
        # ØªÙ†ÙÙŠØ° Ù…Ø¨Ø³Ø· Ù„Ù„ØªØ­Ø³Ù† Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
        uncertainty = self._calculate_uncertainty(interaction)
        
        # Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ† Ù…Ù† Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù†Ø´Ø·ÙŠÙ† Ø£ÙƒØ«Ø± Ù‚ÙŠÙ…Ø©
        user_activity = interaction.context.get('user_activity_level', 0.5)
        
        expected_improvement = uncertainty * user_activity
        return expected_improvement > 0.6
    
    def make_query(self, interaction: InteractionRecord) -> bool:
        """ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"""
        if self.queries_made >= self.query_budget:
            return False
        
        # ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ù‡Ø°Ø§ Ø³ÙŠØ±Ø³Ù„ Ø·Ù„Ø¨ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ³Ù…ÙŠØ©
        # Ù„Ù„Ø¨Ø³Ø§Ø·Ø©ØŒ Ø³Ù†ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù†Ø¬Ø­
        
        self.queries_made += 1
        logger.info(f"â“ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù†Ø´Ø· #{self.queries_made}: {interaction.user_id} -> {interaction.item_id}")
        
        return True
    
    def get_query_statistics(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù†Ø´Ø·"""
        return {
            'total_queries': self.queries_made,
            'remaining_budget': self.query_budget - self.queries_made,
            'uncertain_samples_count': len(self.uncertain_samples),
            'average_uncertainty': np.mean([s['uncertainty'] for s in self.uncertain_samples]) if self.uncertain_samples else 0,
            'query_rate': self.queries_made / max(1, len(self.uncertain_samples))
        }


class ContinuousLearningEngine:
    """
    Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    Main Continuous Learning Engine
    """
    
    def __init__(self, base_model: nn.Module, config: LearningConfig):
        self.config = config
        self.base_model = base_model
        
        # Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.experience_replay = ExperienceReplay(config)
        self.drift_detector = ConceptDriftDetector(config)
        self.online_learner = OnlineLearner(base_model, config)
        self.active_learner = ActiveLearner(config)
        
        # Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        self.model_ensemble = [base_model]
        self.model_performances = [0.8]  # Ø£Ø¯Ø§Ø¡ Ø§ÙØªØ±Ø§Ø¶ÙŠ
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù…
        self.total_interactions = 0
        self.learning_sessions = 0
        self.last_update_time = datetime.now()
        
        # Ø®ÙŠØ· Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±
        self.learning_thread = None
        self.is_learning_active = False
        
    def process_interaction(self, user_id: str, item_id: str, 
                          interaction_type: str, rating: float,
                          context: Dict[str, Any], 
                          features: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ØªÙØ§Ø¹Ù„ Ø¬Ø¯ÙŠØ¯"""
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„
        interaction = InteractionRecord(
            user_id=user_id,
            item_id=item_id,
            interaction_type=interaction_type,
            rating=rating,
            context=context,
            features=features
        )
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ØªÙØ§Ø¹Ù„ Ù‚Ø¨Ù„ Ø§Ù„ØªØ¹Ù„Ù…
        if features is not None:
            with torch.no_grad():
                self.base_model.eval()
                feature_tensor = torch.FloatTensor(features).unsqueeze(0)
                prediction = self.base_model(feature_tensor).item()
                interaction.prediction = prediction
        
        # Ø­ÙØ¸ ÙÙŠ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø®Ø¨Ø±Ø©
        self.experience_replay.store_interaction(interaction)
        
        # Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù†Ø´Ø·
        query_made = False
        if self.config.strategy == LearningStrategy.ACTIVE:
            if self.active_learner.should_query(interaction):
                query_made = self.active_learner.make_query(interaction)
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¹Ø¯Ø§Ø¯
        self.total_interactions += 1
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ Ø­Ø§Ù† Ø§Ù„ÙˆÙ‚Øª
        update_triggered = False
        if self._should_update_model():
            update_triggered = self._trigger_model_update()
        
        return {
            'interaction_processed': True,
            'prediction': interaction.prediction,
            'query_made': query_made,
            'update_triggered': update_triggered,
            'total_interactions': self.total_interactions
        }
    
    def _should_update_model(self) -> bool:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        # ØªØ­Ø¯ÙŠØ« Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª
        if self.total_interactions % self.config.update_frequency == 0:
            return True
        
        # ØªØ­Ø¯ÙŠØ« Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙ‚Øª
        time_since_update = (datetime.now() - self.last_update_time).total_seconds()
        if time_since_update > 3600:  # ÙƒÙ„ Ø³Ø§Ø¹Ø©
            return True
        
        # ØªØ­Ø¯ÙŠØ« Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙƒØ´Ù Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù
        if len(self.experience_replay.memory) >= 100:
            recent_interactions = list(self.experience_replay.memory)[-50:]
            if self._detect_urgent_update_needed(recent_interactions):
                return True
        
        return False
    
    def _detect_urgent_update_needed(self, recent_interactions: List[InteractionRecord]) -> bool:
        """ÙƒØ´Ù Ø§Ù„Ø­Ø§Ø¬Ø© Ø§Ù„Ø¹Ø§Ø¬Ù„Ø© Ù„Ù„ØªØ­Ø¯ÙŠØ«"""
        # ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ø³Ø· Ù„Ù„Ø­Ø§Ø¬Ø© Ø§Ù„Ø¹Ø§Ø¬Ù„Ø©
        prediction_errors = []
        
        for interaction in recent_interactions:
            if interaction.prediction is not None:
                error = abs(interaction.prediction - interaction.rating)
                prediction_errors.append(error)
        
        if prediction_errors:
            avg_error = np.mean(prediction_errors)
            return avg_error > 1.0  # Ø®Ø·Ø£ Ø¹Ø§Ù„ÙŠ
        
        return False
    
    def _trigger_model_update(self) -> bool:
        """ØªØ´ØºÙŠÙ„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹ÙŠÙ†Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
            if self.config.strategy == LearningStrategy.MINI_BATCH:
                batch = self.experience_replay.sample_batch(
                    self.config.batch_size, "importance"
                )
            elif self.config.strategy == LearningStrategy.ONLINE:
                batch = self.experience_replay.sample_batch(1, "recent")
            else:
                batch = self.experience_replay.sample_batch(
                    self.config.batch_size, "diverse"
                )
            
            if not batch:
                return False
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            update_results = self.online_learner.update_model(batch)
            
            # ÙƒØ´Ù Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…ÙŠ
            if 'mse' in update_results:
                accuracy = 1 / (1 + update_results['mse'])  # ØªÙ‚Ø±ÙŠØ¨ Ù„Ù„Ø¯Ù‚Ø©
                predictions = [interaction.prediction for interaction in batch 
                             if interaction.prediction is not None]
                
                features_array = np.array([interaction.features for interaction in batch 
                                         if interaction.features is not None])
                
                self.drift_detector.update_performance(
                    accuracy, predictions, features_array if len(features_array) > 0 else None
                )
                
                # ÙƒØ´Ù Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù
                drift_detected, drift_type, severity = self.drift_detector.detect_drift()
                
                if drift_detected:
                    self._handle_concept_drift(drift_type, severity)
            
            # ØªØ­Ø¯ÙŠØ« ÙˆÙ‚Øª Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«
            self.last_update_time = datetime.now()
            self.learning_sessions += 1
            
            logger.info(f"ğŸ“ Ø¬Ù„Ø³Ø© ØªØ¹Ù„Ù… #{self.learning_sessions} - Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª: {self.total_interactions}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}")
            return False
    
    def _handle_concept_drift(self, drift_type: ConceptDriftType, severity: float):
        """Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…ÙŠ"""
        logger.warning(f"ğŸ”„ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù†Ø­Ø±Ø§Ù Ù…ÙØ§Ù‡ÙŠÙ…ÙŠ: {drift_type.value} (Ø´Ø¯Ø©: {severity:.3f})")
        
        if drift_type == ConceptDriftType.SUDDEN and severity > 0.2:
            # Ø§Ù†Ø­Ø±Ø§Ù Ù…ÙØ§Ø¬Ø¦ Ù‚ÙˆÙŠ - Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø³Ø±ÙŠØ¹
            self._rapid_retraining()
            
        elif drift_type == ConceptDriftType.GRADUAL:
            # Ø§Ù†Ø­Ø±Ø§Ù ØªØ¯Ø±ÙŠØ¬ÙŠ - Ø²ÙŠØ§Ø¯Ø© Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…
            current_lr = self.online_learner.optimizer.param_groups[0]['lr']
            new_lr = min(current_lr * 1.5, 0.01)
            
            for param_group in self.online_learner.optimizer.param_groups:
                param_group['lr'] = new_lr
                
        elif drift_type == ConceptDriftType.RECURRING:
            # Ø§Ù†Ø­Ø±Ø§Ù Ù…ØªÙƒØ±Ø± - Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…ÙˆØ³Ù…ÙŠ
            self._adapt_to_recurring_pattern()
        
        # ØªÙ‚Ù„ÙŠÙ„ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        self._decay_old_experiences(severity)
    
    def _rapid_retraining(self):
        """Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø³Ø±ÙŠØ¹ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬"""
        logger.info("âš¡ Ø¨Ø¯Ø¡ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø³Ø±ÙŠØ¹...")
        
        # Ø¬Ù„Ø¨ Ø¹ÙŠÙ†Ø© ÙƒØ¨ÙŠØ±Ø© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        large_batch = self.experience_replay.sample_batch(
            min(500, len(self.experience_replay.memory)), "recent"
        )
        
        if large_batch:
            # ØªØ¯Ø±ÙŠØ¨ Ù…ÙƒØ«Ù
            for _ in range(10):
                self.online_learner.update_model(large_batch)
    
    def _adapt_to_recurring_pattern(self):
        """Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©"""
        # ØªÙ†ÙÙŠØ° Ù…Ø¨Ø³Ø· - ÙŠÙ…ÙƒÙ† ØªØ·ÙˆÙŠØ±Ù‡ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©
        logger.info("ğŸ”„ Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…ØªÙƒØ±Ø±...")
        
        # Ø²ÙŠØ§Ø¯Ø© ÙˆØ²Ù† Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù„Ù†Ù…Ø·
        for interaction in list(self.experience_replay.memory)[-100:]:
            interaction.importance_weight *= 1.2
    
    def _decay_old_experiences(self, decay_factor: float):
        """ØªÙ‚Ù„ÙŠÙ„ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        for i in range(len(self.experience_replay.importance_weights)):
            self.experience_replay.importance_weights[i] *= (1 - decay_factor * 0.1)
    
    def evaluate_model_performance(self, test_interactions: List[InteractionRecord]) -> Dict[str, float]:
        """ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        if not test_interactions:
            return {}
        
        predictions = []
        actuals = []
        
        self.base_model.eval()
        with torch.no_grad():
            for interaction in test_interactions:
                if interaction.features is not None:
                    feature_tensor = torch.FloatTensor(interaction.features).unsqueeze(0)
                    prediction = self.base_model(feature_tensor).item()
                    
                    predictions.append(prediction)
                    actuals.append(interaction.rating)
        
        if not predictions:
            return {}
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        mse = mean_squared_error(actuals, predictions)
        mae = np.mean(np.abs(np.array(predictions) - np.array(actuals)))
        
        # Ø¯Ù‚Ø© Ø§Ù„ØªØµÙ†ÙŠÙ (Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø³Ø£Ù„Ø© ØªØµÙ†ÙŠÙ)
        binary_predictions = [1 if p > 0.5 else 0 for p in predictions]
        binary_actuals = [1 if a > 0.5 else 0 for a in actuals]
        accuracy = accuracy_score(binary_actuals, binary_predictions)
        
        return {
            'mse': mse,
            'mae': mae,
            'rmse': np.sqrt(mse),
            'accuracy': accuracy
        }
    
    def get_learning_insights(self) -> Dict[str, Any]:
        """Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¹Ù„Ù…"""
        memory_stats = self.experience_replay.get_memory_stats()
        learning_stats = self.online_learner.get_learning_statistics()
        drift_summary = self.drift_detector.get_drift_summary()
        query_stats = self.active_learner.get_query_statistics()
        
        return {
            'system_overview': {
                'total_interactions': self.total_interactions,
                'learning_sessions': self.learning_sessions,
                'learning_strategy': self.config.strategy.value,
                'last_update': self.last_update_time.isoformat()
            },
            'memory_management': memory_stats,
            'learning_progress': learning_stats,
            'concept_drift': drift_summary,
            'active_learning': query_stats,
            'model_ensemble': {
                'ensemble_size': len(self.model_ensemble),
                'average_performance': np.mean(self.model_performances)
            }
        }
    
    def save_learning_state(self, filepath: str):
        """Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù…"""
        logger.info(f"ğŸ’¾ Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± ÙÙŠ {filepath}")
        
        # Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        torch.save(self.base_model.state_dict(), f"{filepath}_model.pth")
        
        # Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        system_state = {
            'config': self.config,
            'total_interactions': self.total_interactions,
            'learning_sessions': self.learning_sessions,
            'model_performances': self.model_performances,
            'memory': list(self.experience_replay.memory),
            'importance_weights': list(self.experience_replay.importance_weights),
            'drift_alerts': self.drift_detector.drift_alerts,
            'learning_history': list(self.online_learner.learning_history),
            'save_timestamp': datetime.now().isoformat()
        }
        
        with open(f"{filepath}_state.pkl", 'wb') as f:
            pickle.dump(system_state, f)
        
        logger.info("âœ… ØªÙ… Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±")
    
    def load_learning_state(self, filepath: str):
        """ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù…"""
        logger.info(f"ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù…Ù† {filepath}")
        
        try:
            # ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            self.base_model.load_state_dict(torch.load(f"{filepath}_model.pth"))
            
            # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
            with open(f"{filepath}_state.pkl", 'rb') as f:
                system_state = pickle.load(f)
            
            self.config = system_state['config']
            self.total_interactions = system_state['total_interactions']
            self.learning_sessions = system_state['learning_sessions']
            self.model_performances = system_state['model_performances']
            
            # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            self.experience_replay.memory = deque(
                system_state['memory'], 
                maxlen=self.config.memory_size
            )
            self.experience_replay.importance_weights = deque(
                system_state['importance_weights'], 
                maxlen=self.config.memory_size
            )
            
            # Ø§Ø³ØªØ¹Ø§Ø¯Ø© ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù
            self.drift_detector.drift_alerts = system_state['drift_alerts']
            
            # Ø§Ø³ØªØ¹Ø§Ø¯Ø© ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ù„Ù…
            self.online_learner.learning_history = deque(
                system_state['learning_history'], 
                maxlen=1000
            )
            
            logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±")
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù…: {str(e)}")
            raise


# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ· Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    class SimpleRecommendationModel(nn.Module):
        def __init__(self, input_size: int = 10):
            super().__init__()
            self.layers = nn.Sequential(
                nn.Linear(input_size, 64),
                nn.ReLU(),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, 1),
                nn.Sigmoid()
            )
        
        def forward(self, x):
            return self.layers(x)
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªÙƒÙˆÙŠÙ†
    config = LearningConfig(
        strategy=LearningStrategy.MINI_BATCH,
        update_frequency=50,
        learning_rate=0.001
    )
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø­Ø±Ùƒ Ø§Ù„ØªØ¹Ù„Ù…
    model = SimpleRecommendationModel()
    learning_engine = ContinuousLearningEngine(model, config)
    
    # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª
    for i in range(200):
        user_id = f"user_{i % 20}"
        item_id = f"item_{i % 50}"
        interaction_type = random.choice(['view', 'like', 'save', 'share'])
        rating = random.uniform(0, 1)
        context = {
            'device': random.choice(['mobile', 'desktop']),
            'time_of_day': random.randint(0, 23)
        }
        features = np.random.random(10)
        
        result = learning_engine.process_interaction(
            user_id=user_id,
            item_id=item_id,
            interaction_type=interaction_type,
            rating=rating,
            context=context,
            features=features
        )
        
        if i % 50 == 0:
            print(f"ØªÙØ§Ø¹Ù„ {i}: {result}")
    
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¤Ù‰ Ø§Ù„ØªØ¹Ù„Ù…
    insights = learning_engine.get_learning_insights()
    print("\nğŸ“Š Ø±Ø¤Ù‰ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±:")
    print(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª: {insights['system_overview']['total_interactions']}")
    print(f"Ø¬Ù„Ø³Ø§Øª Ø§Ù„ØªØ¹Ù„Ù…: {insights['system_overview']['learning_sessions']}")
    print(f"Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {insights['memory_management']['memory_utilization']:.2%}")
    print(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø³Ø§Ø±Ø©: {insights['learning_progress'].get('recent_average_loss', 'N/A')}")
    
    # Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„Ù…
    learning_engine.save_learning_state("continuous_learning_checkpoint")
